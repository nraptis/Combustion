# ========== ROOT: /Users/naraptis/Desktop/Combustion/image ==========

# ===== bitmap.py =====

# bitmap.py

from __future__ import annotations
from typing import TYPE_CHECKING
from typing import List
import numpy as np
from PIL import Image
from image.rgba import RGBA
from image.convolution_edge_behavior import ConvolutionEdgeBehavior
from typing import Optional
import torch
import torch.nn.functional as F

# ----------------------------------------------------------------------
# Bitmap: rgba[x][y] with OpenCV + Pillow interop
# ----------------------------------------------------------------------

class Bitmap:
    """
    Bitmap with:
        - width, height
        - pixels stored as rgba[x][y] where:
            x = 0..width-1  (left to right)
            y = 0..height-1 (top to bottom)
    """

    def __init__(self, width: int = 0, height: int = 0) -> None:
        self.width: int = 0
        self.height: int = 0
        self.rgba: List[List[RGBA]] = []  # rgba[x][y]
        if width > 0 and height > 0:
            self.allocate(width, height)

    # --------------------------------------------------
    # The ONLY place we allocate the internal rgba array
    # --------------------------------------------------
    def allocate(self, width: int, height: int) -> None:
        """
        Resize the bitmap and allocate internal storage.
        This is the ONLY place rgba[][] is allocated.
        """
        self.width = int(width)
        self.height = int(height)

        # rgba[x][y]
        self.rgba = [
            [RGBA(0, 0, 0, 255) for _y in range(self.height)]
            for _x in range(self.width)
        ]

    # --------------------------------------------------
    # Expansion / copy
    # --------------------------------------------------
    def expand(self, width: int, height: int) -> None:
        """
        Expand this bitmap to at least (width, height).

        Existing pixels are preserved in the top-left corner.
        Newly exposed pixels are filled with opaque black (0,0,0,255).

        If the requested size is smaller than or equal to the current
        size in both dimensions, this is a no-op (no shrinking).
        """
        new_w = int(width)
        new_h = int(height)

        if new_w <= self.width and new_h <= self.height:
            # Nothing to do; we only expand, never shrink.
            return

        old_w = self.width
        old_h = self.height
        old_rgba = self.rgba

        # Allocate new storage
        new_rgba = [
            [RGBA(0, 0, 0, 255) for _y in range(new_h)]
            for _x in range(new_w)
        ]

        copy_w = min(old_w, new_w)
        copy_h = min(old_h, new_h)

        # Copy old pixels into the new buffer (top-left aligned)
        for x in range(copy_w):
            src_col = old_rgba[x]
            dst_col = new_rgba[x]
            for y in range(copy_h):
                src_px = src_col[y]
                dst_px = dst_col[y]
                dst_px.ri = src_px.ri
                dst_px.gi = src_px.gi
                dst_px.bi = src_px.bi
                dst_px.ai = src_px.ai

        # Swap in the new buffer
        self.width = new_w
        self.height = new_h
        self.rgba = new_rgba

    def copy(self) -> "Bitmap":
        """
        Deep copy this bitmap into a new Bitmap instance.
        Pixels are duplicated (no shared RGBA objects).
        """
        result = Bitmap()
        result.allocate(self.width, self.height)
        new_rgba = result.rgba

        for x in range(self.width):
            src_col = self.rgba[x]
            dst_col = new_rgba[x]
            for y in range(self.height):
                src_px = src_col[y]
                dst_px = dst_col[y]
                dst_px.ri = src_px.ri
                dst_px.gi = src_px.gi
                dst_px.bi = src_px.bi
                dst_px.ai = src_px.ai

        return result

    # --------------------------------------------------
    # Loading Methods: load via FileIO + import_pillow
    # --------------------------------------------------
    
    @classmethod
    def with_image(cls, file_path) -> "Bitmap":
        """
        Convenience constructor: create a Bitmap and load an image from
        an explicit file path via FileIO.load_image.
        """
        bmp = cls()
        bmp.load_image(file_path)
        return bmp
    
    @classmethod
    def with_local_image(
        cls,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> "Bitmap":
        """
        Convenience constructor: create a Bitmap and load an image using
        FileIO.load_local_image (which uses FileIO.local for path building).
        """
        bmp = cls()
        bmp.load_local_image(
            subdirectory=subdirectory,
            name=name,
            extension=extension,
        )
        return bmp

    def load_image(self, file_path):
        """
        Create a Bitmap from an explicit file path using FileIO.load_image.
        """
        from filesystem.file_utils import FileUtils
        image = FileUtils.load_image(file_path)
        self.import_pillow(image)
        return self  # optional, enables chaining

    def load_local_image(
        self,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> "Bitmap":
        """
        Create a Bitmap using FileIO.load_local_image
        (which uses FileIO.local for path building).
        """
        from filesystem.file_utils import FileUtils
        image = FileUtils.load_local_image(
            subdirectory=subdirectory,
            name=name,
            extension=extension,
        )
        self.import_pillow(image)
        return self  # optional, enables chaining

    # --------------------------------------------------
    # Import from OpenCV (NumPy array)
    # --------------------------------------------------
    def import_opencv(self, mat: np.ndarray) -> None:
        """
        Import from an OpenCV-style NumPy array.
        Supports:
            - H x W (grayscale)
            - H x W x 3 (BGR)
            - H x W x 4 (BGRA)
        """
        if mat is None:
            raise ValueError("mat is None")

        if mat.ndim == 2:
            # Grayscale: shape = (H, W)
            h, w = mat.shape
            self.allocate(w, h)
            for y in range(h):
                for x in range(w):
                    v = int(mat[y, x])
                    self.rgba[x][y] = RGBA(v, v, v, 255)

        elif mat.ndim == 3:
            h, w, c = mat.shape
            if c not in (3, 4):
                raise ValueError(f"Unsupported channel count: {c}")

            self.allocate(w, h)

            if c == 3:
                # BGR
                for y in range(h):
                    for x in range(w):
                        b, g, r = mat[y, x]
                        self.rgba[x][y] = RGBA(int(r), int(g), int(b), 255)
            elif c == 4:
                # BGRA
                for y in range(h):
                    for x in range(w):
                        b, g, r, a = mat[y, x]
                        self.rgba[x][y] = RGBA(int(r), int(g), int(b), int(a))

        else:
            raise ValueError(f"Unsupported mat.ndim = {mat.ndim}")

    # --------------------------------------------------
    # Import from Pillow Image
    # --------------------------------------------------
    def import_pillow(self, image: Image.Image) -> None:
        """
        Import from a Pillow Image.
        Converts to RGBA first to simplify handling.
        """
        if image is None:
            raise ValueError("image is None")

        img = image.convert("RGBA")
        w, h = img.size
        self.allocate(w, h)

        pixels = img.load()
        for x in range(w):
            for y in range(h):
                r, g, b, a = pixels[x, y]
                self.rgba[x][y] = RGBA(int(r), int(g), int(b), int(a))

    # --------------------------------------------------
    # Export to OpenCV (NumPy array)
    # --------------------------------------------------
    def export_opencv(self) -> np.ndarray:
        """
        Export to an OpenCV-style NumPy array (H x W x 4, BGRA).
        Caller can convert to BGR if desired:
            bgr = bgra[:, :, :3]
        """
        h = self.height
        w = self.width
        mat = np.zeros((h, w, 4), dtype=np.uint8)

        for x in range(w):
            for y in range(h):
                px = self.rgba[x][y]
                # OpenCV expects B, G, R, A
                mat[y, x, 0] = px.bi
                mat[y, x, 1] = px.gi
                mat[y, x, 2] = px.ri
                mat[y, x, 3] = px.ai

        return mat

    # --------------------------------------------------
    # Export to Pillow Image
    # --------------------------------------------------
    def export_pillow(self) -> Image.Image:
        """
        Export to a Pillow RGBA Image.
        """
        img = Image.new("RGBA", (self.width, self.height))
        pixels = img.load()

        for x in range(self.width):
            for y in range(self.height):
                px = self.rgba[x][y]
                pixels[x, y] = (px.ri, px.gi, px.bi, px.ai)

        return img

    # --------------------------------------------------
    # Flood fill: set every pixel to the same RGBA color
    # --------------------------------------------------
    def flood(self, color: RGBA) -> None:
        """
        Set every pixel in this bitmap to the given RGBA color.

        If the bitmap has zero width or height, this is a no-op.
        """
        if self.width <= 0 or self.height <= 0:
            return

        # Use the int components from the input color.
        r = color.ri
        g = color.gi
        b = color.bi
        a = color.ai

        for x in range(self.width):
            col = self.rgba[x]
            for y in range(self.height):
                px = col[y]
                px.ri = r
                px.gi = g
                px.bi = b
                px.ai = a

    # --------------------------------------------------
    # Internal helper: compute overlap for stamping
    # --------------------------------------------------
    def _compute_stamp_bounds(self, glyph: "Bitmap", x: int, y: int):
        """
        Compute the overlapping region between this bitmap (destination)
        and the glyph bitmap (source), given that the glyph's top-left
        should be placed at (x, y) in destination coordinates.

        Returns:
            (start_dx, end_dx, start_dy, end_dy, start_gx, start_gy)
        or None if there is no overlap.
        """
        gw, gh = glyph.width, glyph.height
        dw, dh = self.width, self.height
        if gw <= 0 or gh <= 0 or dw <= 0 or dh <= 0:
            return None
        start_dx = max(x, 0)
        start_dy = max(y, 0)
        end_dx = min(x + gw, dw)
        end_dy = min(y + gh, dh)
        if start_dx >= end_dx or start_dy >= end_dy:
            return None
        start_gx = start_dx - x
        start_gy = start_dy - y
        return (start_dx, end_dx, start_dy, end_dy, start_gx, start_gy)

    # --------------------------------------------------
    # Stamp: overwrite pixels from glyph into this bitmap
    # --------------------------------------------------
    def stamp(self, glyph: "Bitmap", x: int, y: int) -> None:
        """
        Stamp `glyph` onto this bitmap so that glyph (0,0)
        lands at destination (x,y).

        For now, we simply REPLACE the destination pixels with
        the glyph pixels (no alpha blending).

        All edge/off-grid cases are handled gracefully:
        - If the stamp is fully off-screen, nothing happens.
        - If the stamp is partially off-screen, only the visible
            part is drawn.
        """
        bounds = self._compute_stamp_bounds(glyph, x, y)
        if bounds is None:
            return
        start_dx, end_dx, start_dy, end_dy, start_gx, start_gy = bounds
        for dy in range(start_dy, end_dy):
            gy = start_gy + (dy - start_dy)
            for dx in range(start_dx, end_dx):
                gx = start_gx + (dx - start_dx)
                self.rgba[dx][dy] = glyph.rgba[gx][gy]

    # --------------------------------------------------
    # Stamp with classic alpha
    # --------------------------------------------------
    def stamp_alpha(self, glyph: "Bitmap", x: int, y: int) -> None:
        bounds = self._compute_stamp_bounds(glyph, x, y)
        if bounds is None:
            return
        start_dx, end_dx, start_dy, end_dy, start_gx, start_gy = bounds
        for dy in range(start_dy, end_dy):
            gy = start_gy + (dy - start_dy)
            for dx in range(start_dx, end_dx):
                gx = start_gx + (dx - start_dx)
                src_px = glyph.rgba[gx][gy]
                dst_px = self.rgba[dx][dy]
                self.rgba[dx][dy] = RGBA.blend_alpha(src_px, dst_px)
                
    # --------------------------------------------------
    # Stamp with additive blending
    # --------------------------------------------------
    def stamp_additive(self, glyph: "Bitmap", x: int, y: int) -> None:
        bounds = self._compute_stamp_bounds(glyph, x, y)
        if bounds is None:
            return
        start_dx, end_dx, start_dy, end_dy, start_gx, start_gy = bounds
        for dy in range(start_dy, end_dy):
            gy = start_gy + (dy - start_dy)
            for dx in range(start_dx, end_dx):
                gx = start_gx + (dx - start_dx)
                src_px = glyph.rgba[gx][gy]
                dst_px = self.rgba[dx][dy]
                self.rgba[dx][dy] = RGBA.blend_additive(src_px, dst_px)

    # --------------------------------------------------
    # Crop a sub-rectangle into a new Bitmap
    # --------------------------------------------------
    def crop(
        self,
        x: int,
        y: int,
        width: int,
        height: int) -> "Bitmap":
        x = int(x)
        y = int(y)
        width = int(width)
        height = int(height)
        if width <= 0 or height <= 0 or self.width <= 0 or self.height <= 0:
            return Bitmap()
        gw, gh = self.width, self.height
        dw, dh = width, height
        x_offset = -x
        y_offset = -y
        start_dx = max(x_offset, 0)
        start_dy = max(y_offset, 0)
        end_dx = min(x_offset + gw, dw)
        end_dy = min(y_offset + gh, dh)
        if start_dx >= end_dx or start_dy >= end_dy:
            return Bitmap()
        start_gx = start_dx - x_offset
        start_gy = start_dy - y_offset
        crop_w = end_dx - start_dx
        crop_h = end_dy - start_dy
        result = Bitmap(crop_w, crop_h)
        for dy in range(crop_h):
            sy = start_gy + dy
            for dx in range(crop_w):
                sx = start_gx + dx
                result.rgba[dx][dy] = self.rgba[sx][sy]
        return result
    
    def convolve(
        self,
        mask: List[List[float]],
        trim_h: int,
        trim_v: int,
        offset_x: int,
        offset_y: int) -> Bitmap:
        """
        TRIM-only convolution.

        - `mask` is mask[x][y] (your x-major convention).
        - Output size is (self.width - 2*trim_h, self.height - 2*trim_v).
        - Only computes outputs whose entire shifted kernel footprint is in-bounds.
        If trim/offset/mask would sample out of bounds, raises ValueError.
        - `edge_behavior` is intentionally ignored to keep single responsibility.
        """

        # ----------------------------
        # Validate mask geometry
        # ----------------------------
        mask_width = len(mask)
        if mask_width <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")
        mask_height = len(mask[0])
        if mask_height <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")

        for x in range(mask_width):
            if len(mask[x]) != mask_height:
                raise ValueError("Invalid mask supplied: non-rectangular mask (columns have different heights).")

        if (mask_width % 2) != 1 or (mask_height % 2) != 1:
            raise ValueError("Invalid mask supplied, requires odd x odd dimensions.")

        if trim_h < 0 or trim_v < 0:
            raise ValueError("trim_h/trim_v must be >= 0.")

        if self.width <= 0 or self.height <= 0:
            return Bitmap()

        # ----------------------------
        # Output region (TRIM)
        # ----------------------------
        start_x = int(trim_h)
        end_x = int(self.width - trim_h)   # exclusive
        start_y = int(trim_v)
        end_y = int(self.height - trim_v)  # exclusive

        out_w = end_x - start_x
        out_h = end_y - start_y
        if out_w <= 0 or out_h <= 0:
            return Bitmap()

        result = Bitmap(width=out_w, height=out_h)

        # ----------------------------
        # Kernel radii
        # ----------------------------
        rx = mask_width // 2
        ry = mask_height // 2

        # ----------------------------
        # TRIM preflight: shifted footprint must fit for the entire output region
        # ----------------------------
        min_x = start_x - rx + offset_x
        max_x = (end_x - 1) + rx + offset_x
        min_y = start_y - ry + offset_y
        max_y = (end_y - 1) + ry + offset_y

        if min_x < 0 or max_x >= self.width or min_y < 0 or max_y >= self.height:
            raise ValueError(
                f"Invalid TRIM convolution bounds. "
                f"mask={mask_width}x{mask_height} trim=({trim_h},{trim_v}) offset=({offset_x},{offset_y}) "
                f"required sample bounds x:[{min_x},{max_x}] y:[{min_y},{max_y}] "
                f"image={self.width}x{self.height}"
            )

        # ----------------------------
        # Convolution
        # ----------------------------
        for base_x in range(start_x, end_x):
            out_x = base_x - start_x
            for base_y in range(start_y, end_y):
                out_y = base_y - start_y

                sum_r = 0.0
                sum_g = 0.0
                sum_b = 0.0
                sum_a = 0.0

                for shift_x in range(-rx, rx + 1):
                    kx = shift_x + rx
                    src_x = base_x + shift_x + offset_x
                    mask_col = mask[kx]  # mask[x][y] column

                    for shift_y in range(-ry, ry + 1):
                        ky = shift_y + ry
                        src_y = base_y + shift_y + offset_y

                        w = float(mask_col[ky])
                        if w == 0.0:
                            continue

                        px = self.rgba[src_x][src_y]
                        sum_r += float(px.ri) * w
                        sum_g += float(px.gi) * w
                        sum_b += float(px.bi) * w
                        sum_a += float(px.ai) * w

                # Round-to-nearest (weights assumed non-negative)
                ri = RGBA._clamp_int(int(sum_r + 0.5))
                gi = RGBA._clamp_int(int(sum_g + 0.5))
                bi = RGBA._clamp_int(int(sum_b + 0.5))
                ai = RGBA._clamp_int(int(sum_a + 0.5))

                dst = result.rgba[out_x][out_y]
                dst.ri = ri
                dst.gi = gi
                dst.bi = bi
                dst.ai = ai

        return result
    
    def convolve_fast(
        self,
        mask: List[List[float]],
        trim_h: int,
        trim_v: int,
        offset_x: int,
        offset_y: int,
        edge_behavior,  # kept for signature compatibility; ignored (always TRIM)
    ) -> Bitmap:
        """
        Fast TRIM-only convolution.
        Matches your convolve() output semantics (mask[x][y], rounding, clamping, output size).
        """

        # ----------------------------
        # Validate mask geometry
        # ----------------------------
        mask_w = len(mask)
        if mask_w <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")
        mask_h = len(mask[0])
        if mask_h <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")

        for x in range(mask_w):
            if len(mask[x]) != mask_h:
                raise ValueError("Invalid mask supplied: non-rectangular mask (columns have different heights).")

        if (mask_w % 2) != 1 or (mask_h % 2) != 1:
            raise ValueError("Invalid mask supplied, requires odd x odd dimensions.")

        if trim_h < 0 or trim_v < 0:
            raise ValueError("trim_h/trim_v must be >= 0.")

        if self.width <= 0 or self.height <= 0:
            return Bitmap()

        # ----------------------------
        # Output region
        # ----------------------------
        W = self.width
        H = self.height

        start_x = int(trim_h)
        end_x   = int(W - trim_h)   # exclusive
        start_y = int(trim_v)
        end_y   = int(H - trim_v)   # exclusive

        out_w = end_x - start_x
        out_h = end_y - start_y
        if out_w <= 0 or out_h <= 0:
            return Bitmap()

        # ----------------------------
        # Kernel radii
        # ----------------------------
        rx = mask_w // 2
        ry = mask_h // 2

        # ----------------------------
        # TRIM preflight: shifted footprint must fit
        # ----------------------------
        min_x = start_x - rx + offset_x
        max_x = (end_x - 1) + rx + offset_x
        min_y = start_y - ry + offset_y
        max_y = (end_y - 1) + ry + offset_y

        if min_x < 0 or max_x >= W or min_y < 0 or max_y >= H:
            raise ValueError(
                f"Invalid TRIM convolution bounds. "
                f"mask={mask_w}x{mask_h} trim=({trim_h},{trim_v}) offset=({offset_x},{offset_y}) "
                f"required sample bounds x:[{min_x},{max_x}] y:[{min_y},{max_y}] "
                f"image={W}x{H}"
            )

        # ----------------------------
        # Convert input bitmap to NumPy BGRA (H x W x 4)
        # ----------------------------
        src_bgra_u8 = self.export_opencv()  # BGRA uint8, shape (H,W,4)

        # Accumulator in float32
        acc = np.zeros((out_h, out_w, 4), dtype=np.float32)

        # ----------------------------
        # Convert mask[x][y] -> mask_np[ky,kx] as HxW (row-major) for iteration
        # This preserves your mask convention but lets us iterate ky/kx naturally.
        # ----------------------------
        mask_np = np.empty((mask_h, mask_w), dtype=np.float32)
        for x in range(mask_w):
            col = mask[x]
            for y in range(mask_h):
                mask_np[y, x] = float(col[y])

        # ----------------------------
        # Vectorized convolution via slicing per tap
        # (ky,kx loop, but each tap is a big NumPy slice multiply-add)
        # ----------------------------
        for ky in range(mask_h):
            shift_y = ky - ry
            sy0 = start_y + shift_y + offset_y
            sy1 = end_y   + shift_y + offset_y

            for kx in range(mask_w):
                w = float(mask_np[ky, kx])
                if w == 0.0:
                    continue

                shift_x = kx - rx
                sx0 = start_x + shift_x + offset_x
                sx1 = end_x   + shift_x + offset_x

                # src slice is (out_h, out_w, 4)
                acc += src_bgra_u8[sy0:sy1, sx0:sx1, :].astype(np.float32) * w

        # ----------------------------
        # Match your rounding + clamp:
        # int(sum + 0.5) then clamp [0,255]
        # ----------------------------
        out_bgra_u8 = np.clip(acc + 0.5, 0.0, 255.0).astype(np.uint8)

        # ----------------------------
        # Convert back to Bitmap (import_opencv expects BGRA)
        # ----------------------------
        result = Bitmap(out_w, out_h)
        result.import_opencv(out_bgra_u8)
        return result
    
    def convolve_torch(
        self,
        mask: List[List[float]],
        trim_h: int,
        trim_v: int,
        offset_x: int,
        offset_y: int,
        device: str = "cpu",
    ) -> Bitmap:
        """
        TRIM-only convolution using PyTorch as the compute engine.

        Semantics:
        - mask is mask[x][y] (x-major)
        - output size is (W - 2*trim_h, H - 2*trim_v)
        - offset shifts the sampling center like your reference convolve()
        - channel-independent: same kernel applied to B,G,R,A separately (no mixing)
        - returns Bitmap via import_opencv (BGRA)

        Note:
        - Matches your reference within typical tolerance=1 due to float accumulation order.
        """

        # ----------------------------
        # Validate mask geometry
        # ----------------------------
        mask_w = len(mask)
        if mask_w <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")
        mask_h = len(mask[0])
        if mask_h <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")

        for x in range(mask_w):
            if len(mask[x]) != mask_h:
                raise ValueError("Invalid mask supplied: non-rectangular mask (columns have different heights).")

        if (mask_w % 2) != 1 or (mask_h % 2) != 1:
            raise ValueError("Invalid mask supplied, requires odd x odd dimensions.")

        if trim_h < 0 or trim_v < 0:
            raise ValueError("trim_h/trim_v must be >= 0.")

        if self.width <= 0 or self.height <= 0:
            return Bitmap()

        W = self.width
        H = self.height

        start_x = int(trim_h)
        end_x   = int(W - trim_h)    # exclusive
        start_y = int(trim_v)
        end_y   = int(H - trim_v)    # exclusive

        out_w = end_x - start_x
        out_h = end_y - start_y
        if out_w <= 0 or out_h <= 0:
            return Bitmap()

        rx = mask_w // 2
        ry = mask_h // 2

        # TRIM preflight: shifted footprint must fit
        min_x = start_x - rx + offset_x
        max_x = (end_x - 1) + rx + offset_x
        min_y = start_y - ry + offset_y
        max_y = (end_y - 1) + ry + offset_y
        if min_x < 0 or max_x >= W or min_y < 0 or max_y >= H:
            raise ValueError(
                f"Invalid TRIM convolution bounds. "
                f"mask={mask_w}x{mask_h} trim=({trim_h},{trim_v}) offset=({offset_x},{offset_y}) "
                f"required sample bounds x:[{min_x},{max_x}] y:[{min_y},{max_y}] "
                f"image={W}x{H}"
            )

        # ----------------------------
        # Convert mask[x][y] -> mask_np[ky,kx] (row-major)
        # ----------------------------
        mask_np = np.empty((mask_h, mask_w), dtype=np.float32)
        for x in range(mask_w):
            col = mask[x]
            for y in range(mask_h):
                mask_np[y, x] = float(col[y])

        # ----------------------------
        # Export bitmap to BGRA (H,W,4) uint8
        # ----------------------------
        src_bgra_u8 = self.export_opencv()

        # Torch tensors: input [N,C,H,W] float32
        # We keep BGRA channel order to match your import/export bridge.
        x = torch.from_numpy(src_bgra_u8).to(device=device)
        x = x.permute(2, 0, 1).unsqueeze(0).contiguous().float()  # [1,4,H,W]

        # Weight for depthwise conv: [C,1,kH,kW], groups=C
        k = torch.from_numpy(mask_np).to(device=device).float()   # [kH,kW]
        w = k.view(1, 1, mask_h, mask_w).repeat(4, 1, 1, 1)       # [4,1,kH,kW]

        with torch.no_grad():
            full = F.conv2d(x, w, bias=None, stride=1, padding=0, groups=4)  # [1,4,H-kH+1,W-kW+1]

            # Map your (start_x/start_y, offset) into conv output coordinates:
            # conv output (oy,ox) corresponds to input center at (oy+ry, ox+rx)
            # we want center at (base_y+offset_y, base_x+offset_x)
            # base ranges: base_x=start_x..end_x-1, base_y=start_y..end_y-1
            ox0 = start_x + offset_x - rx
            oy0 = start_y + offset_y - ry

            out = full[:, :, oy0:oy0 + out_h, ox0:ox0 + out_w]  # [1,4,out_h,out_w]

            # Match your rounding+clamp: int(sum + 0.5) then clamp [0,255]
            out_u8 = torch.clamp(out + 0.5, 0.0, 255.0).to(torch.uint8)

        # Back to numpy BGRA (H,W,4)
        out_bgra_u8 = out_u8.squeeze(0).permute(1, 2, 0).contiguous().cpu().numpy()

        # Import to Bitmap
        result = Bitmap(out_w, out_h)
        result.import_opencv(out_bgra_u8)
        return result

    def compare(self, bitmap: Optional[Bitmap], tolerance: int) -> bool:
        if not bitmap:
            return False
        if self.width != bitmap.width:
            return False
        if self.height != bitmap.height:
            return False
        for x in range(self.width):
            for y in range(self.height):
                if abs(self.rgba[x][y].ri - bitmap.rgba[x][y].ri) > tolerance:
                    return False
                if abs(self.rgba[x][y].gi - bitmap.rgba[x][y].gi) > tolerance:
                    return False
                if abs(self.rgba[x][y].bi - bitmap.rgba[x][y].bi) > tolerance:
                    return False
                if abs(self.rgba[x][y].ai - bitmap.rgba[x][y].ai) > tolerance:
                    return False
        return True
                

    """
    def convolve(self,
                 mask: List[List[float]],
                 trim_h: int,
                 trim_v: int,
                 offset_x: int,
                 offset_y: int,
                 edge_behavior: ConvolutionEdgeBehavior) -> Bitmap:
        
        mask_width = len(mask)
        mask_height = 0
        if mask_width > 0:
            mask_height = len(mask[0])

        if mask_width <= 0 or mask_height <= 0:
            raise ValueError("Invalid mask supplied, requires non-zero dimensions.")
        
        if (mask_width % 2) != 1 or (mask_height % 2) != 1:
            raise ValueError("Invalid mask supplied, requires odd x odd dimensions.")
        
        mask_width_2 = mask_width // 2
        start_x = trim_h
        end_x = self.width - trim_h
        if start_x - mask_width_2 + offset_x < 0:
            raise ValueError("Invalid mask and offset. " + str(mask_width) + str("x") + str(mask_height) + " mask, " + str(offset_x) + str("x") + str(offset_y) + " offset.")
        if end_x + mask_width_2 + offset_x > self.width:
            raise ValueError("Invalid mask and offset. " + str(mask_width) + str("x") + str(mask_height) + " mask, " + str(offset_x) + str("x") + str(offset_y) + " offset.")
        
        mask_height_2 = mask_height // 2
        start_y = trim_h
        end_y = self.height - trim_v
        if start_y - mask_height_2 + offset_y < 0:
            raise ValueError("Invalid mask and offset. " + str(mask_width) + str("x") + str(mask_height) + " mask, " + str(offset_x) + str("x") + str(offset_y) + " offset.")
        if end_y + mask_height_2 + offset_y > self.height:
            raise ValueError("Invalid mask and offset. " + str(mask_width) + str("x") + str(mask_height) + " mask, " + str(offset_x) + str("x") + str(offset_y) + " offset.")
        

        result = Bitmap(width=self.width-(trim_h + trim_h), height=self.height-(trim_v + trim_v))

        # switch edge_behavior:



        for base_x in range(start_x, end_x):
            for base_y in range(start_y, end_y):
                sum_r = float(0.0)
                sum_g = float(0.0)
                sum_b = float(0.0)
                sum_a = float(0.0)

                for shift_x in range(-mask_width_2, mask_width_2 + 1):
                    x = base_x + shift_x + offset_x
                    for shift_y in range(-mask_height_2, mask_height_2 + 1):
                        y = base_y + shift_y + offset_y

                        mask_factor = mask[shift_x + mask_width_2][shift_y + mask_height_2]

                        acc_r = float(self.rgba[x][y].ri) * mask_factor
                        acc_g = float(self.rgba[x][y].gi) * mask_factor
                        acc_b = float(self.rgba[x][y].bi) * mask_factor
                        acc_a = float(self.rgba[x][y].ai) * mask_factor

                        sum_r += acc_r
                        sum_g += acc_g
                        sum_b += acc_b
                        sum_a += acc_a
                
                ri = RGBA._clamp_int(int(sum_r + 0.5))
                gi = RGBA._clamp_int(int(sum_g + 0.5))
                bi = RGBA._clamp_int(int(sum_b + 0.5))
                ai = RGBA._clamp_int(int(sum_a + 0.5))

                result.rgba[base_x - trim_h][base_y - trim_v].ri = ri
                result.rgba[base_x - trim_h][base_y - trim_v].gi = gi
                result.rgba[base_x - trim_h][base_y - trim_v].bi = bi
                result.rgba[base_x - trim_h][base_y - trim_v].ai = ai

        return result
    """


# ===== convolution_edge_behavior.py =====

from enum import Enum, auto

class ConvolutionEdgeBehavior(Enum):
    """
    Defines how convolution handles samples that fall outside the bitmap.
    """

    TRIM = auto()
    """
    Do not sample outside the bitmap.
    Output image is smaller (valid convolution).
    """

    COPY = auto()
    """
    Clamp coordinates to the nearest valid pixel.
    (Edge pixels are repeated outward.)
    """

    BLACK = auto()
    """
    Treat out-of-bounds samples as black (0,0,0,0).
    """



# ===== rgba.py =====

# rgba.py

class RGBA:

    __slots__ = ("_r", "_g", "_b", "_a")

    def __init__(self, r: int, g: int, b: int, a: int = 255):
        self._r = self._clamp_int(r)
        self._g = self._clamp_int(g)
        self._b = self._clamp_int(b)
        self._a = self._clamp_int(a)

    # ------------------------------
    # Helpers
    # ------------------------------
    @staticmethod
    def _clamp_int(v):
        return max(0, min(255, int(v)))

    @staticmethod
    def _clamp_float(v):
        return max(0.0, min(1.0, float(v)))

    # ------------------------------
    # Integer accessors (0–255)
    # ------------------------------
    @property
    def ri(self):
        return self._r

    @ri.setter
    def ri(self, v):
        self._r = self._clamp_int(v)

    @property
    def gi(self):
        return self._g

    @gi.setter
    def gi(self, v):
        self._g = self._clamp_int(v)

    @property
    def bi(self):
        return self._b

    @bi.setter
    def bi(self, v):
        self._b = self._clamp_int(v)

    @property
    def ai(self):
        return self._a

    @ai.setter
    def ai(self, v):
        self._a = self._clamp_int(v)

    # ------------------------------
    # Float accessors (0.0–1.0)
    # ------------------------------
    @property
    def rf(self):
        return self._r / 255.0

    @rf.setter
    def rf(self, v):
        self._r = int(self._clamp_float(v) * 255)

    @property
    def gf(self):
        return self._g / 255.0

    @gf.setter
    def gf(self, v):
        self._g = int(self._clamp_float(v) * 255)

    @property
    def bf(self):
        return self._b / 255.0

    @bf.setter
    def bf(self, v):
        self._b = int(self._clamp_float(v) * 255)

    @property
    def af(self):
        return self._a / 255.0

    @af.setter
    def af(self, v):
        self._a = int(self._clamp_float(v) * 255)

   # ------------------------------
    # Utility
    # ------------------------------
    @classmethod
    def to_gray(cls, r, g, b) -> float:
        return (
            0.299 * r
            + 0.587 * g
            + 0.114 * b
        )
    
    def to_gray(self) -> int:
        gray = 0.299 * self._r + 0.587 * self._g + 0.114 * self._g
        return self._clamp_int(round(gray))
    
    def tuple(self):
        return (self._r, self._g, self._b, self._a)
    
    def __str__(self):
        return f"({self.rf:0.2f}, {self.gf:0.2f}, {self.bf:0.2f}, {self.af:0.2f})"

    def __repr__(self):
        return self.__str__()
    
    # ------------------------------
    # Blending helpers (OpenGL-style)
    # ------------------------------
    @staticmethod
    def blend_alpha(src: "RGBA", dst: "RGBA") -> "RGBA":
        """
        Classic alpha blending:
        glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)
        """
        sa = src.af
        da = dst.af

        out_a = sa + da * (1.0 - sa)
        if out_a == 0.0:
            return RGBA(0, 0, 0, 0)

        out_r = src.rf * sa + dst.rf * (1.0 - sa)
        out_g = src.gf * sa + dst.gf * (1.0 - sa)
        out_b = src.bf * sa + dst.bf * (1.0 - sa)

        return RGBA(
            int(out_r * 255),
            int(out_g * 255),
            int(out_b * 255),
            int(out_a * 255),
        )

    @staticmethod
    def blend_additive(src: "RGBA", dst: "RGBA") -> "RGBA":
        """
        Additive blending:
        glBlendFunc(GL_SRC_ALPHA, GL_ONE)
        """
        sa = src.af
        da = dst.af

        out_a = min(1.0, sa + da)

        out_r = src.rf * sa + dst.rf
        out_g = src.gf * sa + dst.gf
        out_b = src.bf * sa + dst.bf

        # No manual clamp needed: RGBA(...) constructor clamps 0–255
        return RGBA(
            int(out_r * 255),
            int(out_g * 255),
            int(out_b * 255),
            int(out_a * 255),
        )


# ========== ROOT: /Users/naraptis/Desktop/Combustion/labels ==========

# ===== data_label.py =====

# data_label.py
from __future__ import annotations

from typing import Any, Dict
from labels.pixel_bag import PixelBag

class DataLabel:
    """
    Associates a string name with a PixelBag.

    JSON format:

        {
            "name": "some_label_name",
            "pixels": [ { "y": ..., "x_start": ..., "x_end": ... }, ... ]
        }
    """

    def __init__(self, name: str, pixel_bag: PixelBag | None = None) -> None:
        self.name: str = name
        self.pixel_bag: PixelBag = pixel_bag if pixel_bag is not None else PixelBag()


    # --------------------------------------------------
    # PixelBag passthrough wrappers
    # --------------------------------------------------
    def clear(self) -> None:
        self.pixel_bag.clear()

    def add(self, x: int, y: int) -> None:
        self.pixel_bag.add(x, y)

    def remove(self, x: int, y: int) -> None:
        self.pixel_bag.remove(x, y)

    def contains(self, x: int, y: int) -> bool:
        return self.pixel_bag.contains(x, y)

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "pixels": self.pixel_bag.to_json(),
        }

    @staticmethod
    def from_json(data: Dict[str, Any]) -> "DataLabel":
        name = data.get("name", "")
        pixels_json = data.get("pixels", [])
        bag = PixelBag.from_json(pixels_json)
        return DataLabel(name=name, pixel_bag=bag)

    # --------------------------------------------------
    # Utility / debug printing (summary style)
    # --------------------------------------------------
    def __repr__(self) -> str:
        """
        One-line compact summary, e.g.:

            DataLabel(name="lymph",
                      bag=PixelBag(count=100, median=(15,35), size=(10,10)))

        If bag is empty:

            DataLabel(name="lymph", bag=PixelBag(count=0))
        """
        return f'DataLabel(name="{self.name}", bag={self.pixel_bag})'



# ===== data_label_collection.py =====

# data_label_collection.py
from __future__ import annotations

from typing import Any, Dict, List, Iterable

from labels.data_label import DataLabel

class DataLabelCollection:
    """
    A simple list of DataLabel objects.

    Multiple labels may share the same name. Each DataLabel typically
    represents one instance (one PixelBag region).
    """

    def __init__(self, labels: List[DataLabel] | None = None) -> None:
        self.labels: List[DataLabel] = labels or []

    # --------------------------------------------------
    # Basic operations
    # --------------------------------------------------
    def add_label(self, label: DataLabel) -> None:
        """
        Append a label. Multiple labels may have the same name.
        """
        self.labels.append(label)

    def remove_label(self, label: DataLabel) -> None:
        """
        Remove this exact label object from the collection, if present.
        Does nothing if the label is not in the collection.
        """
        try:
            self.labels.remove(label)
        except ValueError:
            # label not in list; ignore
            pass

    def get_labels_by_name(self, name: str) -> List[DataLabel]:
        """
        Return all labels whose name matches the given name.
        May return an empty list.
        """
        return [lbl for lbl in self.labels if lbl.name == name]

    def first_label(self, name: str) -> DataLabel | None:
        """
        Convenience: return the first label with this name, or None.
        """
        for lbl in self.labels:
            if lbl.name == name:
                return lbl
        return None

    # --------------------------------------------------
    # JSON serialization (array only)
    # --------------------------------------------------
    def to_json(self) -> List[Dict[str, Any]]:
        """
        Return a JSON-compatible list of label dicts, no wrapper.
        """
        return [label.to_json() for label in self.labels]

    @staticmethod
    def from_json(data: List[Dict[str, Any]]) -> "DataLabelCollection":
        """
        Parse a list of label objects.
        """
        labels = [DataLabel.from_json(item) for item in data]
        return DataLabelCollection(labels=labels)

    # --------------------------------------------------
    # Helpers
    # --------------------------------------------------
    def __len__(self):
        return len(self.labels)

    def __iter__(self) -> Iterable[DataLabel]:
        return iter(self.labels)

    def _sorted_labels(self) -> List[DataLabel]:
        """
        Return labels sorted by:
          1) name (alphabetical)
          2) median.y  (ascending)
          3) median.x  (ascending)

        Uses PixelBag.summary().median so we don't have to look at stripes.
        Empty bags get a large sentinel so they sort last within a name.
        """
        if not self.labels:
            return []

        def sort_key(label: DataLabel):
            name = label.name
            summary = label.pixel_bag.summary()
            median = summary.get("median")

            if median is None:
                # Empty bag: push to the end for that name
                my = 10**9
                mx = 10**9
            else:
                mx, my = median  # median is (x, y)

            return (name, my, mx)

        return sorted(self.labels, key=sort_key)

    def __repr__(self) -> str:
        """
        Compact summary of the collection plus one-line summary per label, e.g.:

            DataLabelCollection(count=2):
                DataLabel(name="basal", bag=PixelBag(...))
                DataLabel(name="lymph", bag=PixelBag(...))
        """
        count = len(self.labels)
        if count == 0:
            return "DataLabelCollection(count=0)"

        lines: List[str] = [f"DataLabelCollection(count={count}):"]
        for label in self._sorted_labels():
            lines.append(f"    {label!r}")
        return "\n".join(lines)
    


# ===== image_annotation_document.py =====

# image_annotation_document.py
from __future__ import annotations

from typing import Any, Dict, List
from labels.data_label_collection import DataLabelCollection

class ImageAnnotationDocument:
    """
    Top-level container for annotations for a single image.

    Fields:
      - name:             Logical name for this document (often the JSON filename).
      - width:            Image width in pixels.
      - height:           Image height in pixels.
      - data:             DataLabelCollection holding all individual labels.
      - data_label_names: Derived list of label names present in `data`.
    """

    def __init__(
        self,
        name: str,
        width: int,
        height: int,
        data: DataLabelCollection | None = None,
    ) -> None:
        self.name: str = name
        self.width: int = int(width)
        self.height: int = int(height)
        # data is conceptually non-optional; default to empty collection if None
        self.data: DataLabelCollection = data if data is not None else DataLabelCollection()

    # --------------------------------------------------
    # Derived properties
    # --------------------------------------------------
    @property
    def data_label_names(self) -> List[str]:
        """
        Return a sorted list of unique label names present in this document's data.
        """
        names = {label.name for label in self.data}
        return sorted(names)

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> Dict[str, Any]:
        """
        Return a JSON-compatible dict representing this document.

        Layout:

        {
          "name":             str,
          "width":            int,
          "height":           int,
          "data_label_names": [str, ...],
          "labels":           [ ... DataLabel.to_json() ... ]
        }

        Note: data_label_names is derived from `data` at serialization time.
        """
        return {
            "name": self.name,
            "width": self.width,
            "height": self.height,
            "data_label_names": self.data_label_names,
            "labels": self.data.to_json(),
        }

    @staticmethod
    def from_json(data: Dict[str, Any]) -> "ImageAnnotationDocument":
        """
        Parse an ImageAnnotationDocument from a JSON-compatible dict.

        data_label_names from JSON are currently ignored as a source of truth,
        since they can always be recomputed from the label data. They are
        still read (if present) to allow future validation if desired.
        """
        name = data.get("name", "")
        width = int(data.get("width", 0))
        height = int(data.get("height", 0))

        labels_raw = data.get("labels", []) or []
        dlc = DataLabelCollection.from_json(labels_raw)

        # data_label_names = data.get("data_label_names", [])  # optional; not required

        return ImageAnnotationDocument(
            name=name,
            width=width,
            height=height,
            data=dlc,
        )

    # --------------------------------------------------
    # Debug / repr
    # --------------------------------------------------
    def __repr__(self) -> str:
        """
        Compact summary plus an indented listing of labels via
        DataLabelCollection.__repr__.

        Example:

            ImageAnnotationDocument(name="sample_01",
                                    size=(256, 256),
                                    data_label_names=['Alphacyte', 'Lymphocyte'],
                                    label_count=3):
                DataLabel(name="Alphacyte", bag=PixelBag(...))
                DataLabel(name="Lymphocyte", bag=PixelBag(...))
                ...
        """
        label_count = len(self.data)
        header = (
            f'ImageAnnotationDocument('
            f'name="{self.name}", '
            f'size=({self.width}, {self.height}), '
            f'data_label_names={self.data_label_names}, '
            f'label_count={label_count})'
        )

        if label_count == 0:
            return header

        # Indent the DataLabelCollection repr by 4 spaces
        dlc_lines = repr(self.data).splitlines()
        indented_dlc = "\n".join("    " + line for line in dlc_lines)

        return header + ":\n" + indented_dlc



# ===== pixel_bag.py =====

# pixel_bag.py
from __future__ import annotations
from typing import Any, List
from labels.pixel_bag_run_length import PixelBagRunLength
from labels.pixel_bag_run_length_stripe import PixelBagRunLengthStripe

class PixelBag:
    """
    Stores a set of (x, y) integer pixel positions.
    Does not store duplicates (internally a set),
    but add/remove semantics allow double-add and remove-nonexistent
    without raising exceptions.
    """

    def __init__(self) -> None:
        self._set = set()   # stores (x, y)

    # --------------------------------------------------
    # Basic operations
    # --------------------------------------------------
    def clear(self) -> None:
        self._set.clear()

    def add(self, x: int, y: int) -> None:
        """Add a pixel. Adding an existing pixel is allowed and ignored."""
        self._set.add((int(x), int(y)))

    def remove(self, x: int, y: int) -> None:
        """Remove a pixel. Removing a missing pixel is allowed and ignored."""
        self._set.discard((int(x), int(y)))  # discard() never raises

    def contains(self, x: int, y: int) -> bool:
        """Check if a pixel exists in the bag."""
        return (int(x), int(y)) in self._set

    # --------------------------------------------------
    # Bounding box helpers
    # --------------------------------------------------
    @property
    def xmin(self):
        if not self._set:
            return None
        return min(px for (px, _) in self._set)

    @property
    def xmax(self):
        if not self._set:
            return None
        return max(px for (px, _) in self._set)

    @property
    def ymin(self):
        if not self._set:
            return None
        return min(py for (_, py) in self._set)

    @property
    def ymax(self):
        if not self._set:
            return None
        return max(py for (_, py) in self._set)
    
    @property
    def frame(self):
        if not self._set:
            return (0, 0, 0, 0)

        xr = self.xrange()
        yr = self.yrange()
        
        width  = xr.stop - xr.start
        height = yr.stop - yr.start

        return (xr.start, yr.start, width, height)

    # --------------------------------------------------
    # Ranges for easy looping
    # --------------------------------------------------
    def xrange(self):
        """
        Return range(xmin, xmax+1).
        If empty, return range(0).
        """
        if not self._set:
            return range(0)
        return range(self.xmin, self.xmax + 1)

    def yrange(self):
        """
        Return range(ymin, ymax+1).
        If empty, return range(0).
        """
        if not self._set:
            return range(0)
        return range(self.ymin, self.ymax + 1)

    # --------------------------------------------------
    # Utility
    # --------------------------------------------------
    def __len__(self):
        return len(self._set)

    def __iter__(self):
        """Iterate over (x, y) pairs."""
        return iter(self._set)

    def summary(self) -> dict:
        """
        Return summary statistics:

            {
            "count": int,
            "median": (x_med, y_med) | None,
            "size": (width, height)
            }

        width  = xmax - xmin + 1
        height = ymax - ymin + 1
        """
        count = len(self._set)
        if count == 0:
            return {
                "count": 0,
                "median": None,
                "size": (0, 0),
            }

        xs = [x for (x, _) in self._set]
        ys = [y for (_, y) in self._set]

        xs_sorted = sorted(xs)
        ys_sorted = sorted(ys)
        mid = count // 2

        median_x = xs_sorted[mid]
        median_y = ys_sorted[mid]

        xmin = self.xmin
        xmax = self.xmax
        ymin = self.ymin
        ymax = self.ymax

        width = (xmax - xmin + 1) if xmin is not None and xmax is not None else 0
        height = (ymax - ymin + 1) if ymin is not None and ymax is not None else 0

        return {
            "count": count,
            "median": (median_x, median_y),
            "size": (width, height),
        }


    def __repr__(self):
        """
        Compact one-line summary:

            PixelBag(count=67, median=(46,77), size=(80, 111))
        """
        info = self.summary()
        count = info["count"]

        if count == 0:
            return "PixelBag(count=0)"

        mx, my = info["median"]
        w, h = info["size"]

        return (
            f"PixelBag(count={count}, "
            f"median=({mx}, {my}), "
            f"size=({w}, {h}))"
        )


    # --------------------------------------------------
    # Run-length conversion
    # --------------------------------------------------
    def to_run_length(self) -> "PixelBagRunLength":
        result = PixelBagRunLength()

        _xmin = self.xmin
        _xmax = self.xmax
        if _xmin is None or _xmax is None:
            return result

        for y in self.yrange():
            x = _xmin
            while x <= _xmax:
                if self.contains(x, y):
                    x_start = x
                    x_end = x
                    x += 1
                    while x <= _xmax and self.contains(x, y):
                        x_end = x
                        x += 1
                    result.add_stripe(PixelBagRunLengthStripe(y, x_start, x_end))
                else:
                    x += 1
        return result

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> List[Any]:
        """
        Serialize this PixelBag to a JSON-compatible list of run-length
        stripe objects:
            [ { "y": ..., "x_start": ..., "x_end": ... }, ... ]
        """
        rle = self.to_run_length()
        return rle.to_json()

    @staticmethod
    def from_json(data: List[Any]) -> "PixelBag":
        """
        Deserialize a PixelBag from a JSON-compatible list produced
        by PixelBag.to_json().

        Reconstructs all (x, y) pixels from the run-length stripes.
        """
        rle = PixelBagRunLength.from_json(data)
        bag = PixelBag()
        for stripe in rle.stripes:
            y = stripe.y
            for x in range(stripe.x_start, stripe.x_end + 1):
                bag.add(x, y)
        return bag



# ===== pixel_bag_run_length.py =====

# pixel_bag_run_length.py
from __future__ import annotations
from typing import Any, Iterable, List

from labels.pixel_bag_run_length_stripe import PixelBagRunLengthStripe

class PixelBagRunLength:
    """
    Run-length representation of a PixelBag:
    a list of horizontal stripes.
    """

    def __init__(self, stripes: List[PixelBagRunLengthStripe] | None = None) -> None:
        self.stripes: List[PixelBagRunLengthStripe] = stripes or []

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> List[Any]:
        return [stripe.to_json() for stripe in self.stripes]

    @staticmethod
    def from_json(data: List[Any]) -> "PixelBagRunLength":
        stripes = [PixelBagRunLengthStripe.from_json(item) for item in data]
        return PixelBagRunLength(stripes=stripes)

    # --------------------------------------------------
    # Utility
    # --------------------------------------------------
    def add_stripe(self, stripe: PixelBagRunLengthStripe) -> None:
        self.stripes.append(stripe)

    def __len__(self) -> int:
        return len(self.stripes)

    def __iter__(self):
        return iter(self.stripes)

    # -------- central sorting helper --------
    @staticmethod
    def sorted_stripes(
        stripes: Iterable[PixelBagRunLengthStripe],
    ) -> List[PixelBagRunLengthStripe]:
        return sorted(stripes, key=lambda s: (s.y, s.x_start))

    def sorted(self) -> List[PixelBagRunLengthStripe]:
        return PixelBagRunLength.sorted_stripes(self.stripes)

    # --------------------------------------------------
    # One-line summary repr
    # --------------------------------------------------
    def __repr__(self) -> str:
        """
        Compact one-line summary:
        PixelBagRunLength(count=3, stripes=[Stripe(y=10,3→5), Stripe(y=11,7→7)])
        """
        if not self.stripes:
            return "PixelBagRunLength(count=0, stripes=[])"

        parts = []
        for s in self.sorted():
            parts.append(f"Stripe(y={s.y},{s.x_start}→{s.x_end})")

        stripes_str = ", ".join(parts)
        return f"PixelBagRunLength(count={len(self.stripes)}, stripes=[{stripes_str}])"



# ===== pixel_bag_run_length_stripe.py =====

# pixel_bag_run_length_stripe.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict

@dataclass
class PixelBagRunLengthStripe:
    """
    Represents a horizontal run of pixels at a fixed y:
        x in [x_start, x_end] inclusive.
    """
    y: int
    x_start: int
    x_end: int

    def to_json(self) -> Dict[str, Any]:
        """
        Serialize this stripe to a JSON-compatible dict.
        """
        return {
            "y": int(self.y),
            "x_start": int(self.x_start),
            "x_end": int(self.x_end),
        }

    @staticmethod
    def from_json(data: Dict[str, Any]) -> "PixelBagRunLengthStripe":
        """
        Deserialize a stripe from a JSON-compatible dict.
        Expects keys: "y", "x_start", "x_end".
        """
        return PixelBagRunLengthStripe(
            y=int(data["y"]),
            x_start=int(data["x_start"]),
            x_end=int(data["x_end"]),
        )

    # --------------------------------------------------
    # Debug / printing helpers
    # --------------------------------------------------
    def repr_str(self, indent: int = 0) -> str:
        """
        Return a single-line string representation, with leading tabs
        based on indent depth.
        """
        prefix = "\t" * max(indent, 0)
        return f"{prefix}(y={self.y}, x_start={self.x_start}, x_end={self.x_end})"

    def __repr__(self) -> str:
        """
        Default repr with no indentation.
        """
        return self.repr_str(indent=0)



# ========== ROOT: /Users/naraptis/Desktop/Combustion/filesystem ==========

# ===== file_io.py =====

# file_io.py

from __future__ import annotations

from pathlib import Path
from typing import Union, List

PathLike = Union[str, Path]

class FileIO:

    # ================================================================
    # Path builders: directories + files
    # ================================================================

    @classmethod
    def local_directory(cls, subdirectory: PathLike | None = None) -> Path:
        """
        Build a fully-qualified directory path inside the project root.
        Strips any leading/trailing slashes.
        """
        project_root = Path(__file__).resolve().parent.parent

        if subdirectory:
            subdirectory = cls._strip_outer_slashes(str(subdirectory))
            return (project_root / subdirectory).resolve()

        return project_root

    @classmethod
    def local_file(
        cls,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> Path:
        """
        Build a fully-resolved file path inside the project using the
        familiar subdirectory + name + extension pattern.

        Example:
            local_file("images", "cat", "png")
            -> ROOT/images/cat.png
        """
        if name is None or len(name.strip()) == 0:
            raise ValueError("local_file requires a non-empty 'name'")

        # Clean outer slashes
        if subdirectory:
            subdirectory = cls._strip_outer_slashes(subdirectory)
        name = cls._strip_outer_slashes(name)

        name_path = Path(name)

        # Extension override
        if extension:
            extension = extension.lstrip(".")
            parent = name_path.parent
            stem = name_path.stem

            if str(parent) == ".":
                file_name = f"{stem}.{extension}"
            else:
                file_name = str(parent / f"{stem}.{extension}")
        else:
            file_name = name

        root = Path(__file__).resolve().parent.parent
        if subdirectory:
            final_path = root / subdirectory / file_name
        else:
            final_path = root / file_name

        return final_path.resolve()

    # ================================================================
    # FILE LISTING (FLAT + RECURSIVE)
    # ================================================================

    @classmethod
    def get_all_files(cls, directory: PathLike) -> List[Path]:
        """
        Return all direct (non-directory) files in directory.
        """
        dir_path = cls._to_path(directory)
        if not dir_path.exists():
            return []
        return [p for p in dir_path.iterdir() if p.is_file()]

    @classmethod
    def get_all_files_local(cls, subdirectory: PathLike) -> List[Path]:
        folder = cls.local_directory(subdirectory)
        return cls.get_all_files(folder)

    @classmethod
    def get_all_files_recursive(cls, directory: PathLike) -> List[Path]:
        """
        Return all files in all nested subdirectories.
        """
        dir_path = cls._to_path(directory)
        if not dir_path.exists():
            return []
        return [p for p in dir_path.rglob("*") if p.is_file()]

    @classmethod
    def get_all_files_local_recursive(cls, subdirectory: PathLike) -> List[Path]:
        folder = cls.local_directory(subdirectory)
        return cls.get_all_files_recursive(folder)

    # ================================================================
    # Helpers
    # ================================================================

    @classmethod
    def _strip_outer_slashes(cls, s: str) -> str:
        if not isinstance(s, str):
            raise TypeError("Path must be a string")
        return s.lstrip("/\\").rstrip("/\\")

    @classmethod
    def _ensure_parent_dir(cls, path: Path) -> None:
        parent = path.parent
        if not parent.exists():
            parent.mkdir(parents=True, exist_ok=True)

    @classmethod
    def _to_path(cls, p: PathLike) -> Path:
        if isinstance(p, Path):
            return p.resolve()
        return Path(p).resolve()

    # ================================================================
    # Core I/O: bytes only
    # ================================================================

    @classmethod
    def load(cls, file_path: PathLike) -> bytes:
        """
        Load raw bytes from an explicit path.

        Caller decides how to interpret the bytes (text, image, etc.).
        """
        path = cls._to_path(file_path)

        if not path.is_file():
            raise FileNotFoundError(f"File not found: {path}")

        return path.read_bytes()

    @classmethod
    def load_local(
        cls,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> bytes:
        """
        Build a local file path via local_file() and load raw bytes.
        """
        path = cls.local_file(subdirectory=subdirectory, name=name, extension=extension)
        return cls.load(path)

    @classmethod
    def save(cls, data: bytes, file_path: PathLike) -> Path:
        """
        Save raw bytes to a specific path.

        - Creates parent directories if needed.
        - Returns the resolved Path actually written.
        """
        path = cls._to_path(file_path)
        cls._ensure_parent_dir(path)
        path.write_bytes(data)
        return path

    @classmethod
    def save_local(
        cls,
        data: bytes,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> Path:
        """
        Build a local file path via local_file() and save raw bytes there.
        """
        path = cls.local_file(subdirectory=subdirectory, name=name, extension=extension)
        return cls.save(data, path)



# ===== file_utils.py =====

# file_utils.py
from __future__ import annotations
from typing import TYPE_CHECKING

from pathlib import Path
from typing import Optional

from filesystem.file_io import FileIO
from image.bitmap import Bitmap
from PIL import Image

if TYPE_CHECKING:
    # Only imported for type checkers / IDEs, not at runtime
    from image.bitmap import Bitmap

class FileUtils:

    # ================================================================
    # TEXT UTILITIES
    # ================================================================

    @classmethod
    def load_text(cls, file_path: Path, encoding: str = "utf-8") -> str:
        data = FileIO.load(file_path)
        return data.decode(encoding)

    @classmethod
    def load_local_text(cls, subdirectory: Optional[str], name: str, extension: str, encoding="utf-8") -> str:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.load_text(path, encoding)

    @classmethod
    def save_text(cls, text: str, file_path: Path, encoding: str = "utf-8") -> Path:
        data = text.encode(encoding)
        return FileIO.save(data, file_path)

    @classmethod
    def save_local_text(cls, text: str, subdirectory: Optional[str], name: str, extension: str, encoding="utf-8") -> Path:
        data = text.encode(encoding)
        return FileIO.save_local(data, subdirectory, name, extension)

    # ================================================================
    # IMAGE UTILITIES
    # ================================================================

    @classmethod
    def load_image(cls, file_path: Path) -> Image.Image:
        path = Path(file_path).resolve()
        if path.is_file():
            image = Image.open(path)
            if image is not None:
                image.load()
                if image.width > 0 and image.height > 0:
                    return image
        base = path.with_suffix("")
        for extension in [".png", ".PNG", ".jpg", ".JPG", ".jpeg", ".JPEG", ".tif", ".tiff"]:
            attempt_path = base.with_suffix(extension)
            if attempt_path.is_file():
                image = Image.open(attempt_path)
                if image is not None:
                    image.load()
                    if image.width > 0 and image.height > 0:
                        return image
        raise FileNotFoundError(f"Image not found: {path}")
    
    @classmethod
    def load_bitmap(cls, file_path: Path) -> Bitmap:
        image = cls.load_image(file_path)
        bitmap = Bitmap()
        bitmap.import_pillow(image)
        return bitmap

    @classmethod
    def load_local_image(cls, subdirectory: Optional[str], name: str, extension=None) -> Image.Image:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.load_image(path)
    
    @classmethod
    def load_local_bitmap(cls, subdirectory: Optional[str], name: str, extension=None) -> Bitmap:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.load_bitmap(path)

    @classmethod
    def save_image(cls, image: Image.Image, file_path: Path) -> Path:
        path = Path(file_path).resolve()
        FileIO._ensure_parent_dir(path)
        image.save(path)
        return path

    @classmethod
    def save_local_image(cls, image: Image.Image, subdirectory: Optional[str], name: str, extension="png") -> Path:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.save_image(image, path)
    
    @classmethod
    def save_local_bitmap(cls, bitmap: Optional[Bitmap], subdirectory: Optional[str], name: str, extension="png") -> Path:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.save_image(bitmap.export_pillow(), path)



