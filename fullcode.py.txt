# ========== ROOT: /Users/naraptis/Desktop/Combustion/scorch ==========

# ===== annotation_loader.py =====

# scorch/annotation_loader.py
import json
from pathlib import Path
from filesystem.file_io import FileIO
from labels.image_annotation_document import ImageAnnotationDocument


class AnnotationLoadError(Exception):
    """Raised when an annotation JSON file cannot be parsed or validated."""
    pass


def load_annotation_document(path: str | Path) -> ImageAnnotationDocument:
    """
    Load an annotation JSON file safely from an absolute path.
    - We assume `path` is absolute or resolvable to absolute.
    """
    p = Path(path).resolve()

    # --- Stage 1: load raw bytes ---
    try:
        raw_bytes = FileIO.load(p)
    except Exception as e:
        raise AnnotationLoadError(f"Failed to read file: {p}") from e

    # --- Stage 2: decode UTF-8 ---
    try:
        text = raw_bytes.decode("utf-8")
    except Exception as e:
        raise AnnotationLoadError(f"Invalid UTF-8 in file: {p}") from e

    # --- Stage 3: JSON parse ---
    try:
        data = json.loads(text)
    except json.JSONDecodeError as e:
        raise AnnotationLoadError(f"Malformed JSON in file: {p}") from e

    # --- Stage 4: convert to ImageAnnotationDocument ---
    try:
        return ImageAnnotationDocument.from_json(data)
    except Exception as e:
        raise AnnotationLoadError(
            f"Invalid annotation structure in file: {p}"
        ) from e



# ===== data_loader.py =====

# scorch/data_loader.py
from __future__ import annotations
from dataclasses import dataclass
from pathlib import Path
from typing import Iterator, List

from filesystem.file_io import FileIO
from labels.image_annotation_document import ImageAnnotationDocument
from .annotation_loader import load_annotation_document, AnnotationLoadError


@dataclass
class AnnotationImagePair:
    """
    Holds a full annotation document and the matching image path on disk.
    """
    document: ImageAnnotationDocument
    image_path: Path

# scorch/data_loader.py  (continued)

class DataLoader:
    """
    Generic loader that:
      - finds all annotation JSON files via FileIO.get_all_files_local
      - loads each into an ImageAnnotationDocument
      - verifies the corresponding PNG image exists (name + ".png")
      - yields AnnotationImagePair objects
    """

    def __init__(self, annotations_subdir: str, images_subdir: str | None = None):
        """
        annotations_subdir: project-local subdirectory where *_annotations.json live
        images_subdir:      project-local subdirectory where PNG images live
                            (defaults to the same as annotations_subdir)
        """
        self.annotations_subdir = annotations_subdir
        self.images_subdir = images_subdir or annotations_subdir

        # --- Discover annotation files ---
        all_files: List[Path] = FileIO.get_all_files_local(
            subdirectory=self.annotations_subdir
        )

        # Keep only files that look like annotation JSONs.
        self.annotation_files: List[Path] = sorted(
            f for f in all_files
            if f.suffix == ".json" and f.name.endswith("_annotations.json")
        )
        
        seen = set()
        self.documents = []
        class_names = set()
        for annotation_path in self.annotation_files:
            try:
                document = load_annotation_document(annotation_path)
                name = document.name
                if name in seen:
                    print("DUPE NAME??? ", name)
                    continue
                seen.add(name)
                self.documents.append(document)
                for label_name in document.data_label_names:
                    class_names.add(label_name)
            except AnnotationLoadError as e:
                print(f"[DataLoader] Skipping corrupt file: {annotation_path}\n  {e}")
                continue  # skip but keep going
        self.class_names = list(class_names)

    def __len__(self) -> int:
        return len(self.annotation_files)

    def __iter__(self):
        for document in self.documents:
            name = document.name

            # build image path
            img_rel = Path(self.images_subdir) / f"{name}.png"
            img_path = FileIO.local_file(name=str(img_rel)).resolve()

            if not img_path.exists():
                print(f"[DataLoader] Missing PNG for '{name}', skipping.")
                continue

            yield AnnotationImagePair(document=document, image_path=img_path)




# ===== grad_check.py =====

# scorch/grad_check.py
from __future__ import annotations

import numpy as np

from scorch.scorch_sequential import ScorchSequential
from scorch.scorch_linear_2 import ScorchLinear2
from scorch.scorch_relu_2 import ScorchReLU2


def softmax_and_cross_entropy_with_grad(logits: np.ndarray, target_index: int):
    """
    Same as in your runner, but local here for convenience.
    """
    shifted = logits - np.max(logits)
    exp = np.exp(shifted)
    probs = exp / np.sum(exp)

    loss = -np.log(probs[target_index] + 1e-12)

    grad = probs.copy()
    grad[target_index] -= 1.0

    return float(loss), grad


def compute_loss(model: ScorchSequential, x: np.ndarray, target_index: int) -> float:
    """
    Forward through the model and return scalar loss for a single (x, y).
    No gradient computation here, pure forward.
    """
    logits = model.forward(x)  # (C,)
    loss, _ = softmax_and_cross_entropy_with_grad(logits, target_index)
    return loss


def compute_loss_and_backprop(model: ScorchSequential, x: np.ndarray, target_index: int):
    """
    Forward + backward for a single sample.
    Returns:
        loss (float)
    and fills model's gradients via backward().
    """
    model.zero_grad()

    logits = model.forward(x)
    loss, grad_logits = softmax_and_cross_entropy_with_grad(logits, target_index)
    _ = model.backward(grad_logits)

    return loss


def grad_check_weight(
    model: ScorchSequential,
    x: np.ndarray,
    target_index: int,
    layer_idx: int,
    i: int,
    j: int,
    eps: float = 1e-4,
):
    """
    Compare analytic grad_W[i,j] vs numeric finite-difference gradient on a given layer.

    layer_idx:
        index in model.layers where the ScorchLinear2 lives.

    i, j:
        indices into that layer's W matrix.
    """
    layer = model.layers[layer_idx]
    if not isinstance(layer, ScorchLinear2):
        raise TypeError(f"Layer at index {layer_idx} is not ScorchLinear2: {type(layer)}")

    W = layer.W

    # --- 1) Analytic gradient via backprop ---
    _ = compute_loss_and_backprop(model, x, target_index)
    analytic = layer.grad_W[i, j]

    # --- 2) Numeric gradient via finite differences ---
    original = W[i, j]

    # W[i, j] + eps
    W[i, j] = original + eps
    loss_plus = compute_loss(model, x, target_index)

    # W[i, j] - eps
    W[i, j] = original - eps
    loss_minus = compute_loss(model, x, target_index)

    # Restore original weight
    W[i, j] = original

    numeric = (loss_plus - loss_minus) / (2.0 * eps)

    # --- 3) Print comparison ---
    print(f"[grad_check] layer={layer_idx}, W[{i},{j}]")
    print(f"  analytic: {analytic}")
    print(f"  numeric : {numeric}")
    print(f"  diff    : {abs(analytic - numeric)}")

    return analytic, numeric



# ===== nn_functional.py =====

# scorch/nn_functional.py
from __future__ import annotations
import numpy as np

def linear_forward(x: np.ndarray, W: np.ndarray, b: np.ndarray) -> np.ndarray:
    """

    W is the matrix of learned weights.
    linear_forward applies those weights to
    the input features to compute the output
    neuron activations. These activations
    propagate forward to the next layer,
    or become the final “logits” used
    by the network to make predictions.

    Pure function: y = W @ x + b

    x: (D,)
    W: (C, D)
    b: (C,)
    returns: (C,)
    """

    #return W @ x + b

    
    C = W.shape[0]   # number of output neurons
    D = W.shape[1]   # number of input features

    # Safety check
    if x.shape[0] != D:
        raise ValueError(f"linear_forward: Expected x of shape ({D},), got {x.shape}")

    z = [0.0 for _ in range(C)]

    for i in range(C):         # for every output neuron
        acc = 0.0
        for j in range(D):     # multiply across the row of W
            acc += W[i, j] * x[j]
        acc += b[i]            # add bias
        z[i] = acc

    return np.array(z, dtype=np.float32)


def softmax_cross_entropy(logits: np.ndarray, target_index: int) -> float:
    """
    Pure function: softmax + cross-entropy loss for a single example.

    logits is the output from linear forward … a 1-D list of floats.
    target_index is the correct class label as an integer.

    logits: (C,)
    target_index: int in [0, C)

    Classes:
        0 = cat
        1 = dog
        2 = fish

    logits = [1.5, 0.2, -0.3]
    target_index = 2 (this is expected to be "fish")

    Interpretation:
        cat: 1.5
        dog: 0.2
        fish: -0.3

    ...

    exp([1.5, 0.2, -0.3]) → normalized → probs

    probs ≈ [0.65, 0.23, 0.12]

    Which means:
        Model thinks “cat” with probability 65%
        Model thinks “dog” with probability 23%
        Model thinks “fish” with probability 12%

    This was expected as fish, so it will be a high loss...

    loss = - log(prob_of_correct_class)
    loss = - log(0.12)
    loss ≈ 2.12  (a high loss)

    """
    # For numerical stability
    shifted = logits - np.max(logits)
    exp = np.exp(shifted)
    probs = exp / np.sum(exp)

    # Cross entropy loss: -log p_target
    loss = -np.log(probs[target_index] + 1e-12)
    return float(loss)



# ===== scorch_dataset.py =====

# scorch/scorch_dataset.py

from __future__ import annotations
from typing import List, Tuple, Dict

import torch
from torch.utils.data import Dataset

from scorch.data_loader import DataLoader
from scorch.tensor_load_helpers import iter_label_patches_from_pair
from scorch.scorch_tensor import ScorchTensor


class ScorchPatchClassificationDataset(Dataset):
    """
    Simple classification dataset:
      - walks your DataLoader (annotations + images)
      - uses image patches (from PixelBag frames) as inputs
      - uses label.name as the class
      - ignores masks for now (we're just doing classification)
    """

    def __init__(
        self,
        annotations_subdir: str,
        images_subdir: str | None = None,
        grayscale: bool = True,
    ) -> None:
        super().__init__()

        self.grayscale = grayscale
        self.class_to_index: Dict[str, int] = {}
        self.index_to_class: List[str] = []
        self.samples: List[Tuple[ScorchTensor, int]] = []

        loader = DataLoader(
            annotations_subdir=annotations_subdir,
            images_subdir=images_subdir,
        )

        for pair in loader:
            for img_tensor, _mask_tensor, label_name in iter_label_patches_from_pair(
                pair, grayscale=self.grayscale
            ):
                class_idx = self._get_or_add_class_index(label_name)
                self.samples.append((img_tensor, class_idx))

        print(f"[ScorchDataset] Loaded {len(self.samples)} samples "
              f"from {len(self.class_to_index)} classes.")

    # ----------------------------------------
    # Internal helpers
    # ----------------------------------------
    def _get_or_add_class_index(self, label_name: str) -> int:
        if label_name not in self.class_to_index:
            idx = len(self.index_to_class)
            self.class_to_index[label_name] = idx
            self.index_to_class.append(label_name)
        return self.class_to_index[label_name]

    # ----------------------------------------
    # Dataset interface
    # ----------------------------------------
    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int):
        scorch_tensor, class_idx = self.samples[idx]

        # Convert to PyTorch tensor (float32, C,H,W)
        x = scorch_tensor.to_torch()           # torch.float32, C,H,W
        y = torch.tensor(class_idx, dtype=torch.long)
        return x, y



# ===== scorch_linear.py =====

# scorch/scorch_linear.py
from __future__ import annotations
import math
import numpy as np

from scorch.nn_functional import linear_forward
from scorch.scorch_module import ScorchModule


class ScorchLinear(ScorchModule):
    """
    A minimal fully-connected layer:
        y = W @ x + b

    Shapes:
        x: (D,)
        W: (C, D)
        b: (C,)
        y: (C,)

    Backward:
        grad_output: dL/dy, shape (C,)
        Produces:
            grad_W: dL/dW, shape (C, D)
            grad_b: dL/db, shape (C,)
            grad_input: dL/dx, shape (D,)
    """

    def __init__(self, in_features: int, out_features: int, name: str | None = None):
        super().__init__()
        self.in_features = int(in_features)
        self.out_features = int(out_features)
        self.name = name or f"ScorchLinear({in_features}->{out_features})"

        # Parameter initialization (Xavier-ish)
        limit = 1.0 / math.sqrt(self.in_features)
        self.W = np.random.uniform(
            -limit, +limit,
            size=(self.out_features, self.in_features)
        ).astype(np.float32)

        self.b = np.zeros((self.out_features,), dtype=np.float32)

        # Gradients
        self.grad_W = np.zeros_like(self.W)
        self.grad_b = np.zeros_like(self.b)

        # Cache for backward
        self._last_x: np.ndarray | None = None

    # ------------------------------------------------------
    # Forward pass
    # ------------------------------------------------------
    def forward(self, x):
        """
        x: np.ndarray of shape (in_features,)
        returns: np.ndarray of shape (out_features,)
        """
        x_arr = np.asarray(x, dtype=np.float32)

        if x_arr.ndim != 1:
            raise ValueError(f"{self.name}: Expected input shape (D,), got {x_arr.shape}")

        if x_arr.shape[0] != self.in_features:
            raise ValueError(
                f"{self.name}: Expected {self.in_features} features, got {x_arr.shape[0]}"
            )

        # Save for backward
        self._last_x = x_arr.copy()

        return linear_forward(x_arr, self.W, self.b)

    # ------------------------------------------------------
    # Backward pass
    # ------------------------------------------------------
    def backward(self, grad_output):
        """
        grad_output: dL/dy, shape (out_features,)

        Computes:
            grad_W (accumulated into self.grad_W)
            grad_b (accumulated into self.grad_b)
        Returns:
            grad_input: dL/dx, shape (in_features,)
        """
        if self._last_x is None:
            raise RuntimeError(f"{self.name}: backward called before forward.")

        g_out = np.asarray(grad_output, dtype=np.float32)

        if g_out.shape != (self.out_features,):
            raise ValueError(
                f"{self.name}: grad_output shape {g_out.shape} "
                f"does not match (out_features,) = ({self.out_features},)"
            )

        x = self._last_x  # shape (D,)

        D = self.in_features
        C = self.out_features

        # dL/dW = outer(grad_output, x)
        # grad_W = np.outer(g_out, x)  # (C, D)

        # grad_W is the rate of change in error loss with respect to weight.
        # ...
        # The derivative of the loss with respect to weight W[i,j].
        # ...
        # grad_W[i,j] ==> “How much would the total loss change if we
        # nudged weight W[i,j] upward by a tiny amount?”

        grad_W = np.zeros((C, D), dtype=np.float32)

        for i in range(C):        # for each output neuron
            for j in range(D):    # for each input feature
                grad_W[i][j] = g_out[i] * x[j]

        # dL/db = grad_output
        grad_b = g_out  # (C,)

        # dL/dx = W^T @ grad_output
        # ...
        # grad_input = Wᵀ @ g_out because each input
        # feature receives error signals from every output
        # neuron, scaled by the weight that connects them...
        # and that weighted sum is a dot product.

        # grad_input = self.W.T @ g_out  # (D,)

        grad_input = np.zeros(D, dtype=np.float32)

        for j in range(D):               # for each input feature x[j]
            acc = 0.0
            for i in range(C):           # sum over all output neurons
                acc += self.W[i][j] * g_out[i]
            grad_input[j] = acc

        # Accumulate gradients (so multiple samples can add up)
        self.grad_W += grad_W
        self.grad_b += grad_b

        return grad_input

    # ------------------------------------------------------
    # Parameter + gradient handling
    # ------------------------------------------------------
    def parameters(self):
        return [self.W, self.b]

    def zero_grad(self):
        self.grad_W.fill(0.0)
        self.grad_b.fill(0.0)

    def __repr__(self):
        return f"{self.name}(W={self.W.shape}, b={self.b.shape})"



# ===== scorch_module.py =====

# scorch/scorch_module.py
from __future__ import annotations

from typing import List, Any


class ScorchModule:
    """
    Minimal base class for all Scorch layers.

    Design goals:
      - Very small surface area.
      - Forward and backward are explicit.
      - Parameter handling is unified (so optimizers can just call .parameters()).

    Subclasses should override:
      - forward(self, x)
      - backward(self, grad_output)
      - parameters(self)         (if they have learnable params)
      - zero_grad(self)          (if they store gradients)
    """

    def forward(self, x: Any) -> Any:
        """
        Compute the forward pass.

        Must be overridden in subclasses.

        Example signature in subclasses:
            x: np.ndarray
            returns: np.ndarray

        Forward = compute values
        Backward = compute sensitivities
        """
        raise NotImplementedError(f"{self.__class__.__name__}.forward not implemented.")

    def backward(self, grad_output: Any) -> Any:
        """
        Compute the backward pass.

        grad_output is dL/d(out) from the next layer.
        This method must compute dL/d(input) and store
        gradients for parameters (if any).

        Chain Rule:
        (dL / dx) = (dL / dy) * (dy / dx)

        (The gradient leaving a node) =
        (The gradient entering that node) *
        (the derivative of the operation the node performs)

        Forward = compute values
        Backward = compute sensitivities
        """
        raise NotImplementedError(f"{self.__class__.__name__}.backward not implemented.")

    # --------------------------------------------------
    # Parameter handling
    # --------------------------------------------------
    def parameters(self) -> List[Any]:
        """
        Return a flat list of all learnable parameters
        owned by this module.

        Layers without parameters can just inherit this
        default (empty list).
        """
        return []

    def zero_grad(self) -> None:
        """
        Reset gradients for all learnable parameters.

        Layers without parameters (e.g. ReLU, MaxPool)
        can inherit this default no-op implementation.
        Layers with parameters should override and zero
        their internal grad arrays.
        """
        # No-op by default
        pass

    # --------------------------------------------------
    # Convenience: allow calling module(x) like in PyTorch
    # --------------------------------------------------
    def __call__(self, x: Any) -> Any:
        return self.forward(x)

    def __repr__(self) -> str:
        return f"{self.__class__.__name__}()"



# ===== scorch_relu.py =====

# scorch/scorch_relu.py
from __future__ import annotations

import numpy as np
from scorch.scorch_module import ScorchModule


class ScorchReLU(ScorchModule):
    """
    Elementwise ReLU activation:

        y = max(0, x)

    Forward:
        - Works on any np.ndarray shape.
        - Stores a mask (x > 0) for backward.

    Backward:
        - grad_input = grad_output * (x > 0)
    """

    def __init__(self, name: str | None = None):
        super().__init__()
        self.name = name or "ScorchReLU"
        self._mask: np.ndarray | None = None

    # ------------------------------------------------------
    # Forward pass
    # ------------------------------------------------------
    def forward(self, x):
        """
        x: np.ndarray (any shape)
        returns: np.ndarray (same shape)
        """
        x_arr = np.asarray(x, dtype=np.float32)

        # Store mask for backward: 1 where x > 0, 0 elsewhere
        self._mask = (x_arr > 0).astype(np.float32)

        # ReLU: max(0, x) == x * (x > 0)
        return x_arr * self._mask

    # ------------------------------------------------------
    # Backward pass
    # ------------------------------------------------------
    def backward(self, grad_output):
        """
        grad_output: dL/dy, same shape as forward output
        returns: dL/dx, same shape as input

        For ReLU:
            dL/dx = dL/dy * 1 where x > 0
            dL/dx = dL/dy * 0 where x <= 0
        """
        if self._mask is None:
            raise RuntimeError(f"{self.name}: backward called before forward.")

        grad_out_arr = np.asarray(grad_output, dtype=np.float32)

        if grad_out_arr.shape != self._mask.shape:
            raise ValueError(
                f"{self.name}: grad_output shape {grad_out_arr.shape} "
                f"does not match mask shape {self._mask.shape}"
            )

        # Elementwise multiply with mask
        grad_input = grad_out_arr * self._mask
        return grad_input

    # ------------------------------------------------------
    # Parameters / grads
    # ------------------------------------------------------
    def parameters(self):
        # ReLU has no learnable parameters
        return []

    def zero_grad(self):
        # Nothing to do; no parameters
        pass

    def __repr__(self):
        return f"{self.name}()"



# ===== scorch_sequential.py =====

# scorch/scorch_sequential.py
from __future__ import annotations

from typing import List

from scorch.scorch_module import ScorchModule


class ScorchSequential(ScorchModule):
    """
    A simple container that holds several ScorchModules and applies them in order.

    Forward pass:
        input → layer_0 → layer_1 → ... → layer_N → output

    Backward pass:
        final gradient → layer_N.backward → ... → layer_1.backward → layer_0.backward

    Parameters:
        Returns all parameters belonging to all child layers.

    zero_grad():
        Clears all stored gradients in every child layer.
    """

    def __init__(self, *layers: ScorchModule):
        """
        Example:
            model = ScorchSequential(
                ScorchLinear(4, 8),
                ScorchReLU(),
                ScorchLinear(8, 3)
            )
        """
        super().__init__()
        self.layers: List[ScorchModule] = list(layers)

    # ------------------------------------------------------
    # Forward pass
    # ------------------------------------------------------
    def forward(self, x):
        """
        Pass the input through each layer in order.

        x: whatever shape the first layer expects (often a 1-D np.ndarray)
        returns: output of the final layer
        """
        out = x
        for layer in self.layers:
            out = layer.forward(out)
        return out

    # ------------------------------------------------------
    # Backward pass
    # ------------------------------------------------------
    def backward(self, grad_output):
        """
        Backpropagate a gradient through all layers in reverse order.

        grad_output:
            The gradient of the loss with respect to the output of
            the last layer. (Often called "dL/dy_last")

        Returns:
            The gradient of the loss with respect to the original input.
            (Often called "dL/dx_first")
        """
        grad = grad_output

        # Traverse layers in reverse order (just like PyTorch)
        for layer in reversed(self.layers):
            grad = layer.backward(grad)

        return grad

    # ------------------------------------------------------
    # Parameter management
    # ------------------------------------------------------
    def parameters(self):
        """
        Collect parameters from every child layer into a single flat list.
        """
        params = []
        for layer in self.layers:
            params.extend(layer.parameters())
        return params

    def zero_grad(self):
        """
        Reset gradient buffers for all child layers.
        """
        for layer in self.layers:
            layer.zero_grad()

    # ------------------------------------------------------
    # Convenience
    # ------------------------------------------------------
    def append(self, layer: ScorchModule):
        """Add a layer to the end."""
        self.layers.append(layer)

    def __len__(self):
        return len(self.layers)

    def __getitem__(self, idx: int):
        return self.layers[idx]

    def __repr__(self):
        inner = ",\n  ".join(repr(layer) for layer in self.layers)
        return f"ScorchSequential(\n  {inner}\n)"



# ===== scorch_tensor.py =====

# scorch/scorch_tensor.py

from __future__ import annotations
from dataclasses import dataclass
from typing import Optional
import numpy as np
from image.bitmap import Bitmap
from image.rgba import RGBA

@dataclass
class ScorchTensor:
    """
    Core numeric tensor type for Scorch.

    Internal Rules:
    - ALWAYS normalized float32 in range [0, 1].
    - ALWAYS channel-first: (C, H, W).
    - C is 1 (grayscale) or 3 (RGB).
    """

    data: np.ndarray                  # MUST be float32 (C,H,W) normalized
    name: Optional[str] = None
    role: str = "generic"             # "image", "mask", etc.

    # ===============================================================
    # Bitmap → ScorchTensor
    # ===============================================================
    @classmethod
    def from_bitmap(
        cls,
        bmp: Bitmap,
        name: Optional[str] = None,
        role: str = "image",
        grayscale: bool = True,
    ) -> "ScorchTensor":
        """
        Convert a Bitmap to a ScorchTensor, ALWAYS normalized to [0,1].
        """
        if bmp.width <= 0 or bmp.height <= 0:
            return cls(np.zeros((0,), dtype=np.float32), name=name, role=role)

        # BGRA uint8 → (H, W, 4)
        bgra = bmp.export_opencv().astype(np.float32)

        # Extract channels
        b = bgra[:, :, 0]
        g = bgra[:, :, 1]
        r = bgra[:, :, 2]

        if grayscale:
            gray = RGBA.luma_from_rgb(r, g, b)     # H,W
            gray /= 255.0                                # normalize
            data = gray[np.newaxis, :, :]                # C=1,H,W
        else:
            r /= 255.0
            g /= 255.0
            b /= 255.0
            data = np.stack([r, g, b], axis=0)           # C=3,H,W

        return cls(data=data.astype(np.float32), name=name, role=role)
    
    @classmethod
    def from_bitmap_crop(
        cls,
        bmp: Bitmap,
        x: int,
        y: int,
        width: int,
        height: int,
        name: Optional[str] = None,
        role: str = "image",
        grayscale: bool = True,
    ) -> "ScorchTensor":
        """
        Crop region → Bitmap.crop → ScorchTensor.
        Always normalized.
        """
        cropped = bmp.crop(
            x=x,
            y=y,
            width=width,
            height=height)
        return cls.from_bitmap(cropped, name=name, role=role, grayscale=grayscale)
    

    # ===============================================================
    # Init hook
    # ===============================================================
    def __post_init__(self) -> None:
        # Force float32
        arr = np.asarray(self.data, dtype=np.float32)

        # Enforce normalization (final safety clamp)
        arr = np.clip(arr, 0.0, 1.0)

        # If 2D: promote to (1,H,W)
        if arr.ndim == 2:
            arr = arr[np.newaxis, :, :]  # grayscale assumption

        # Validate shape
        if arr.ndim != 3:
            raise ValueError(f"ScorchTensor must be 3D (C,H,W), got shape {arr.shape}")

        self.data = arr

    # ===============================================================
    # Introspection
    # ===============================================================
    @property
    def shape(self):
        return self.data.shape

    @property
    def ndim(self):
        return self.data.ndim
    

    def clone(self) -> "ScorchTensor":
        return ScorchTensor(self.data.copy(), name=self.name, role=self.role)

    def flatten(self) -> "ScorchTensor":
        c, h, w = self.data.shape
        return ScorchTensor(self.data.reshape(1, c * h * w), name=self.name, role=self.role)

    # ===============================================================
    # Framework Export
    # ===============================================================
    def to_numpy(self) -> np.ndarray:
        return self.data

    def to_torch(self):
        import torch
        return torch.from_numpy(self.data.copy())

    def to_tf(self):
        import tensorflow as tf
        arr = np.moveaxis(self.data, 0, -1)  # CHW → HWC
        return tf.convert_to_tensor(arr)

    # ===============================================================
    # ScorchTensor → Bitmap (for visualization)
    # ===============================================================
    def to_bitmap(self) -> Bitmap:
        """
        Convert this ScorchTensor back into a Bitmap.

        Assumes:
        - data ∈ [0,1]
        - shape = (C,H,W)
        - C = 1 or 3
        """
        arr = self.data

        if arr.size == 0:
            return Bitmap()

        c, h, w = arr.shape

        if c not in (1, 3):
            raise ValueError(f"Cannot convert tensor with C={c} to Bitmap")

        # Scale back to byte range
        img = np.clip(arr * 255.0, 0, 255).astype(np.uint8)

        # Allocate Bitmap
        bmp = Bitmap(w, h)

        if c == 1:
            # grayscale: broadcast to rgb
            gray = img[0, :, :]
            for x in range(w):
                col = bmp.rgba[x]
                for y in range(h):
                    v = int(gray[y, x])
                    px = col[y]
                    px.ri = v
                    px.gi = v
                    px.bi = v
                    px.ai = 255

        else:
            # RGB channels
            r = img[0, :, :]
            g = img[1, :, :]
            b = img[2, :, :]
            for x in range(w):
                col = bmp.rgba[x]
                for y in range(h):
                    px = col[y]
                    px.ri = int(r[y, x])
                    px.gi = int(g[y, x])
                    px.bi = int(b[y, x])
                    px.ai = 255

        return bmp



# ===== tensor_load_helpers.py =====

# scorch/tensor_load_helpers.py

from __future__ import annotations
from typing import Iterator, Tuple
import numpy as np

from labels.pixel_bag import PixelBag
from scorch.scorch_tensor import ScorchTensor
from image.bitmap import Bitmap
from scorch.data_loader import AnnotationImagePair, DataLoader


# -------------------------------------------------------------------
# Core: mask from PixelBag (cropped to PixelBag.frame)
# -------------------------------------------------------------------
def mask_tensor_from_pixel_bag(
    bag: PixelBag,
    name: str | None = None,
) -> ScorchTensor:
    """
    Create a 1 x H x W mask tensor cropped to the PixelBag's frame.
    Pixels in the bag -> 1.0, everything else -> 0.0.
    """
    x0, y0, w, h = bag.frame

    if w == 0 or h == 0:
        return ScorchTensor(
            np.zeros((0,), dtype=np.float32),
            name=name,
            role="mask",
        )

    mask = np.zeros((1, h, w), dtype=np.float32)

    for x, y in bag:
        mx = x - x0  # local coords inside bbox
        my = y - y0
        if 0 <= mx < w and 0 <= my < h:
            mask[0, my, mx] = 1.0

    return ScorchTensor(mask, name=name, role="mask")


# -------------------------------------------------------------------
# Core: image + mask from PixelBag (one label)
# -------------------------------------------------------------------
def image_and_mask_from_pixel_bag(
    bmp: Bitmap,
    bag: PixelBag,
    name: str | None = None,
    grayscale: bool = True,
) -> Tuple[ScorchTensor, ScorchTensor]:
    """
    Return (image_patch, mask_patch) for a single PixelBag.

    Both tensors are cropped to PixelBag.frame and share the same H, W.
    """
    x0, y0, w, h = bag.frame

    if w == 0 or h == 0:
        empty = ScorchTensor(
            np.zeros((0,), dtype=np.float32),
            name=name,
            role="empty",
        )
        return empty, empty

    # Defensive clamp to bitmap bounds
    x0 = max(0, min(x0, bmp.width  - w))
    y0 = max(0, min(y0, bmp.height - h))

    img_tensor = ScorchTensor.from_bitmap_crop(
        bmp=bmp,
        x=x0,
        y=y0,
        width=w,
        height=h,
        name=f"{name}_img" if name else None,
        role="image_patch",
        grayscale=grayscale,
    )

    mask_tensor = mask_tensor_from_pixel_bag(
        bag=bag,
        name=f"{name}_mask" if name else None,
    )

    # Simple shape sanity check
    _, h_m, w_m = mask_tensor.shape
    _, h_i, w_i = img_tensor.shape
    if (h_m, w_m) != (h_i, w_i):
        raise ValueError(
            f"Mask/image size mismatch: mask=({h_m},{w_m}), image=({h_i},{w_i})"
        )

    return img_tensor, mask_tensor


# -------------------------------------------------------------------
# High-level: iterate (image_patch, mask_patch, label_name) over a pair
# -------------------------------------------------------------------
def iter_label_patches_from_pair(
    pair: AnnotationImagePair,
    grayscale: bool = True,
):
    """
    Yield (image_patch, mask_patch, label_name) for every label
    in a single AnnotationImagePair.
    """
    bmp = Bitmap.with_image(pair.image_path)
    doc = pair.document

    # Adjust attribute names if your document layout differs
    for label in doc.data.labels:
        bag = label.pixel_bag
        img_patch, mask_patch = image_and_mask_from_pixel_bag(
            bmp=bmp,
            bag=bag,
            name=label.name,
            grayscale=grayscale,
        )
        yield img_patch, mask_patch, label.name
        


# ========== ROOT: /Users/naraptis/Desktop/Combustion/image ==========

# ===== bitmap.py =====

# bitmap.py

from __future__ import annotations
from typing import TYPE_CHECKING
from typing import List
import numpy as np
from PIL import Image
from image.rgba import RGBA
from filesystem.file_utils import FileUtils

# ----------------------------------------------------------------------
# Bitmap: rgba[x][y] with OpenCV + Pillow interop
# ----------------------------------------------------------------------

class Bitmap:
    """
    Bitmap with:
        - width, height
        - pixels stored as rgba[x][y] where:
            x = 0..width-1  (left to right)
            y = 0..height-1 (top to bottom)
    """

    def __init__(self, width: int = 0, height: int = 0) -> None:
        self.width: int = 0
        self.height: int = 0
        self.rgba: List[List[RGBA]] = []  # rgba[x][y]
        if width > 0 and height > 0:
            self.set_size(width, height)

    # --------------------------------------------------
    # The ONLY place we allocate the internal rgba array
    # --------------------------------------------------
    def set_size(self, width: int, height: int) -> None:
        """
        Resize the bitmap and allocate internal storage.
        This is the ONLY place rgba[][] is allocated.
        """
        self.width = int(width)
        self.height = int(height)

        # rgba[x][y]
        self.rgba = [
            [RGBA(0, 0, 0, 255) for _y in range(self.height)]
            for _x in range(self.width)
        ]

    # --------------------------------------------------
    # Loading Methods: load via FileIO + import_pillow
    # --------------------------------------------------
    
    @classmethod
    def with_image(cls, file_path) -> "Bitmap":
        """
        Convenience constructor: create a Bitmap and load an image from
        an explicit file path via FileIO.load_image.
        """
        bmp = cls()
        bmp.load_image(file_path)
        return bmp
    
    @classmethod
    def with_local_image(
        cls,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> "Bitmap":
        """
        Convenience constructor: create a Bitmap and load an image using
        FileIO.load_local_image (which uses FileIO.local for path building).
        """
        bmp = cls()
        bmp.load_local_image(
            subdirectory=subdirectory,
            name=name,
            extension=extension,
        )
        return bmp

    def load_image(self, file_path):
        """
        Create a Bitmap from an explicit file path using FileIO.load_image.
        """
        image = FileUtils.load_image(file_path)
        self.import_pillow(image)
        return self  # optional, enables chaining

    def load_local_image(
        self,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> "Bitmap":
        """
        Create a Bitmap using FileIO.load_local_image
        (which uses FileIO.local for path building).
        """
        image = FileUtils.load_local_image(
            subdirectory=subdirectory,
            name=name,
            extension=extension,
        )
        self.import_pillow(image)
        return self  # optional, enables chaining

    # --------------------------------------------------
    # Import from OpenCV (NumPy array)
    # --------------------------------------------------
    def import_opencv(self, mat: np.ndarray) -> None:
        """
        Import from an OpenCV-style NumPy array.
        Supports:
            - H x W (grayscale)
            - H x W x 3 (BGR)
            - H x W x 4 (BGRA)
        """
        if mat is None:
            raise ValueError("mat is None")

        if mat.ndim == 2:
            # Grayscale: shape = (H, W)
            h, w = mat.shape
            self.set_size(w, h)
            for y in range(h):
                for x in range(w):
                    v = int(mat[y, x])
                    self.rgba[x][y] = RGBA(v, v, v, 255)

        elif mat.ndim == 3:
            h, w, c = mat.shape
            if c not in (3, 4):
                raise ValueError(f"Unsupported channel count: {c}")

            self.set_size(w, h)

            if c == 3:
                # BGR
                for y in range(h):
                    for x in range(w):
                        b, g, r = mat[y, x]
                        self.rgba[x][y] = RGBA(int(r), int(g), int(b), 255)
            elif c == 4:
                # BGRA
                for y in range(h):
                    for x in range(w):
                        b, g, r, a = mat[y, x]
                        self.rgba[x][y] = RGBA(int(r), int(g), int(b), int(a))

        else:
            raise ValueError(f"Unsupported mat.ndim = {mat.ndim}")

    # --------------------------------------------------
    # Import from Pillow Image
    # --------------------------------------------------
    def import_pillow(self, image: Image.Image) -> None:
        """
        Import from a Pillow Image.
        Converts to RGBA first to simplify handling.
        """
        if image is None:
            raise ValueError("image is None")

        img = image.convert("RGBA")
        w, h = img.size
        self.set_size(w, h)

        pixels = img.load()
        for x in range(w):
            for y in range(h):
                r, g, b, a = pixels[x, y]
                self.rgba[x][y] = RGBA(int(r), int(g), int(b), int(a))

    # --------------------------------------------------
    # Export to OpenCV (NumPy array)
    # --------------------------------------------------
    def export_opencv(self) -> np.ndarray:
        """
        Export to an OpenCV-style NumPy array (H x W x 4, BGRA).
        Caller can convert to BGR if desired:
            bgr = bgra[:, :, :3]
        """
        h = self.height
        w = self.width
        mat = np.zeros((h, w, 4), dtype=np.uint8)

        for x in range(w):
            for y in range(h):
                px = self.rgba[x][y]
                # OpenCV expects B, G, R, A
                mat[y, x, 0] = px.bi
                mat[y, x, 1] = px.gi
                mat[y, x, 2] = px.ri
                mat[y, x, 3] = px.ai

        return mat

    # --------------------------------------------------
    # Export to Pillow Image
    # --------------------------------------------------
    def export_pillow(self) -> Image.Image:
        """
        Export to a Pillow RGBA Image.
        """
        img = Image.new("RGBA", (self.width, self.height))
        pixels = img.load()

        for x in range(self.width):
            for y in range(self.height):
                px = self.rgba[x][y]
                pixels[x, y] = (px.ri, px.gi, px.bi, px.ai)

        return img

    # --------------------------------------------------
    # Flood fill: set every pixel to the same RGBA color
    # --------------------------------------------------
    def flood(self, color: RGBA) -> None:
        """
        Set every pixel in this bitmap to the given RGBA color.

        If the bitmap has zero width or height, this is a no-op.
        """
        if self.width <= 0 or self.height <= 0:
            return

        # Use the int components from the input color.
        r = color.ri
        g = color.gi
        b = color.bi
        a = color.ai

        for x in range(self.width):
            col = self.rgba[x]
            for y in range(self.height):
                px = col[y]
                px.ri = r
                px.gi = g
                px.bi = b
                px.ai = a


    # --------------------------------------------------
    # Internal helper: compute overlap for stamping
    # --------------------------------------------------
    def _compute_stamp_bounds(self, glyph: "Bitmap", x: int, y: int):
        """
        Compute the overlapping region between this bitmap (destination)
        and the glyph bitmap (source), given that the glyph's top-left
        should be placed at (x, y) in destination coordinates.

        Returns:
            (start_dx, end_dx, start_dy, end_dy, start_gx, start_gy)
        or None if there is no overlap.
        """
        gw, gh = glyph.width, glyph.height
        dw, dh = self.width, self.height
        if gw <= 0 or gh <= 0 or dw <= 0 or dh <= 0:
            return None
        start_dx = max(x, 0)
        start_dy = max(y, 0)
        end_dx = min(x + gw, dw)
        end_dy = min(y + gh, dh)
        if start_dx >= end_dx or start_dy >= end_dy:
            return None
        start_gx = start_dx - x
        start_gy = start_dy - y
        return (start_dx, end_dx, start_dy, end_dy, start_gx, start_gy)

    # --------------------------------------------------
    # Stamp: overwrite pixels from glyph into this bitmap
    # --------------------------------------------------
    def stamp(self, glyph: "Bitmap", x: int, y: int) -> None:
        """
        Stamp `glyph` onto this bitmap so that glyph (0,0)
        lands at destination (x,y).

        For now, we simply REPLACE the destination pixels with
        the glyph pixels (no alpha blending).

        All edge/off-grid cases are handled gracefully:
        - If the stamp is fully off-screen, nothing happens.
        - If the stamp is partially off-screen, only the visible
            part is drawn.
        """
        bounds = self._compute_stamp_bounds(glyph, x, y)
        if bounds is None:
            return
        start_dx, end_dx, start_dy, end_dy, start_gx, start_gy = bounds
        for dy in range(start_dy, end_dy):
            gy = start_gy + (dy - start_dy)
            for dx in range(start_dx, end_dx):
                gx = start_gx + (dx - start_dx)
                self.rgba[dx][dy] = glyph.rgba[gx][gy]

    # --------------------------------------------------
    # Stamp with classic alpha
    # --------------------------------------------------
    def stamp_alpha(self, glyph: "Bitmap", x: int, y: int) -> None:
        bounds = self._compute_stamp_bounds(glyph, x, y)
        if bounds is None:
            return
        start_dx, end_dx, start_dy, end_dy, start_gx, start_gy = bounds
        for dy in range(start_dy, end_dy):
            gy = start_gy + (dy - start_dy)
            for dx in range(start_dx, end_dx):
                gx = start_gx + (dx - start_dx)
                src_px = glyph.rgba[gx][gy]
                dst_px = self.rgba[dx][dy]
                self.rgba[dx][dy] = RGBA.blend_alpha(src_px, dst_px)
                
    # --------------------------------------------------
    # Stamp with additive blending
    # --------------------------------------------------
    def stamp_additive(self, glyph: "Bitmap", x: int, y: int) -> None:
        bounds = self._compute_stamp_bounds(glyph, x, y)
        if bounds is None:
            return
        start_dx, end_dx, start_dy, end_dy, start_gx, start_gy = bounds
        for dy in range(start_dy, end_dy):
            gy = start_gy + (dy - start_dy)
            for dx in range(start_dx, end_dx):
                gx = start_gx + (dx - start_dx)
                src_px = glyph.rgba[gx][gy]
                dst_px = self.rgba[dx][dy]
                self.rgba[dx][dy] = RGBA.blend_additive(src_px, dst_px)


    # --------------------------------------------------
    # Crop a sub-rectangle into a new Bitmap
    # --------------------------------------------------
    def crop(
        self,
        x: int,
        y: int,
        width: int,
        height: int) -> "Bitmap":
        x = int(x)
        y = int(y)
        width = int(width)
        height = int(height)
        if width <= 0 or height <= 0 or self.width <= 0 or self.height <= 0:
            return Bitmap()
        gw, gh = self.width, self.height
        dw, dh = width, height
        x_offset = -x
        y_offset = -y
        start_dx = max(x_offset, 0)
        start_dy = max(y_offset, 0)
        end_dx = min(x_offset + gw, dw)
        end_dy = min(y_offset + gh, dh)
        if start_dx >= end_dx or start_dy >= end_dy:
            return Bitmap()
        start_gx = start_dx - x_offset
        start_gy = start_dy - y_offset
        crop_w = end_dx - start_dx
        crop_h = end_dy - start_dy
        result = Bitmap(crop_w, crop_h)
        for dy in range(crop_h):
            sy = start_gy + dy
            for dx in range(crop_w):
                sx = start_gx + dx
                result.rgba[dx][dy] = self.rgba[sx][sy]
        return result



# ===== rgba.py =====

# rgba.py

class RGBA:

    __slots__ = ("_r", "_g", "_b", "_a")

    def __init__(self, r: int, g: int, b: int, a: int = 255):
        self._r = self._clamp_int(r)
        self._g = self._clamp_int(g)
        self._b = self._clamp_int(b)
        self._a = self._clamp_int(a)

    # ------------------------------
    # Helpers
    # ------------------------------
    @staticmethod
    def _clamp_int(v):
        return max(0, min(255, int(v)))

    @staticmethod
    def _clamp_float(v):
        return max(0.0, min(1.0, float(v)))

    # ------------------------------
    # Integer accessors (0–255)
    # ------------------------------
    @property
    def ri(self):
        return self._r

    @ri.setter
    def ri(self, v):
        self._r = self._clamp_int(v)

    @property
    def gi(self):
        return self._g

    @gi.setter
    def gi(self, v):
        self._g = self._clamp_int(v)

    @property
    def bi(self):
        return self._b

    @bi.setter
    def bi(self, v):
        self._b = self._clamp_int(v)

    @property
    def ai(self):
        return self._a

    @ai.setter
    def ai(self, v):
        self._a = self._clamp_int(v)

    # ------------------------------
    # Float accessors (0.0–1.0)
    # ------------------------------
    @property
    def rf(self):
        return self._r / 255.0

    @rf.setter
    def rf(self, v):
        self._r = int(self._clamp_float(v) * 255)

    @property
    def gf(self):
        return self._g / 255.0

    @gf.setter
    def gf(self, v):
        self._g = int(self._clamp_float(v) * 255)

    @property
    def bf(self):
        return self._b / 255.0

    @bf.setter
    def bf(self, v):
        self._b = int(self._clamp_float(v) * 255)

    @property
    def af(self):
        return self._a / 255.0

    @af.setter
    def af(self, v):
        self._a = int(self._clamp_float(v) * 255)

   # ------------------------------
    # Utility
    # ------------------------------
    @classmethod
    def luma_from_rgb(cls, r, g, b) -> float:
        return (
            0.299 * r
            + 0.587 * g
            + 0.114 * b
        )
    
    def to_gray(self) -> int:
        gray = 0.299 * self._r + 0.587 * self._g + 0.114 * self._g
        return self._clamp_int(round(gray))
    
    def tuple(self):
        return (self._r, self._g, self._b, self._a)
    
    def __str__(self):
        return f"({self.rf:0.2f}, {self.gf:0.2f}, {self.bf:0.2f}, {self.af:0.2f})"

    def __repr__(self):
        return self.__str__()
    
    # ------------------------------
    # Blending helpers (OpenGL-style)
    # ------------------------------
    @staticmethod
    def blend_alpha(src: "RGBA", dst: "RGBA") -> "RGBA":
        """
        Classic alpha blending:
        glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)
        """
        sa = src.af
        da = dst.af

        out_a = sa + da * (1.0 - sa)
        if out_a == 0.0:
            return RGBA(0, 0, 0, 0)

        out_r = src.rf * sa + dst.rf * (1.0 - sa)
        out_g = src.gf * sa + dst.gf * (1.0 - sa)
        out_b = src.bf * sa + dst.bf * (1.0 - sa)

        return RGBA(
            int(out_r * 255),
            int(out_g * 255),
            int(out_b * 255),
            int(out_a * 255),
        )

    @staticmethod
    def blend_additive(src: "RGBA", dst: "RGBA") -> "RGBA":
        """
        Additive blending:
        glBlendFunc(GL_SRC_ALPHA, GL_ONE)
        """
        sa = src.af
        da = dst.af

        out_a = min(1.0, sa + da)

        out_r = src.rf * sa + dst.rf
        out_g = src.gf * sa + dst.gf
        out_b = src.bf * sa + dst.bf

        # No manual clamp needed: RGBA(...) constructor clamps 0–255
        return RGBA(
            int(out_r * 255),
            int(out_g * 255),
            int(out_b * 255),
            int(out_a * 255),
        )


# ========== ROOT: /Users/naraptis/Desktop/Combustion/filesystem ==========

# ===== file_io.py =====

# file_io.py

from __future__ import annotations

from pathlib import Path
from typing import Union, List

PathLike = Union[str, Path]

class FileIO:

    # ================================================================
    # Path builders: directories + files
    # ================================================================

    @classmethod
    def local_directory(cls, subdirectory: PathLike | None = None) -> Path:
        """
        Build a fully-qualified directory path inside the project root.
        Strips any leading/trailing slashes.
        """
        project_root = Path(__file__).resolve().parent.parent

        if subdirectory:
            subdirectory = cls._strip_outer_slashes(str(subdirectory))
            return (project_root / subdirectory).resolve()

        return project_root

    @classmethod
    def local_file(
        cls,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> Path:
        """
        Build a fully-resolved file path inside the project using the
        familiar subdirectory + name + extension pattern.

        Example:
            local_file("images", "cat", "png")
            -> ROOT/images/cat.png
        """
        if name is None or len(name.strip()) == 0:
            raise ValueError("local_file requires a non-empty 'name'")

        # Clean outer slashes
        if subdirectory:
            subdirectory = cls._strip_outer_slashes(subdirectory)
        name = cls._strip_outer_slashes(name)

        name_path = Path(name)

        # Extension override
        if extension:
            extension = extension.lstrip(".")
            parent = name_path.parent
            stem = name_path.stem

            if str(parent) == ".":
                file_name = f"{stem}.{extension}"
            else:
                file_name = str(parent / f"{stem}.{extension}")
        else:
            file_name = name

        root = Path(__file__).resolve().parent.parent
        if subdirectory:
            final_path = root / subdirectory / file_name
        else:
            final_path = root / file_name

        return final_path.resolve()

    # ================================================================
    # FILE LISTING (FLAT + RECURSIVE)
    # ================================================================

    @classmethod
    def get_all_files(cls, directory: PathLike) -> List[Path]:
        """
        Return all direct (non-directory) files in directory.
        """
        dir_path = cls._to_path(directory)
        if not dir_path.exists():
            return []
        return [p for p in dir_path.iterdir() if p.is_file()]

    @classmethod
    def get_all_files_local(cls, subdirectory: PathLike) -> List[Path]:
        folder = cls.local_directory(subdirectory)
        return cls.get_all_files(folder)

    @classmethod
    def get_all_files_recursive(cls, directory: PathLike) -> List[Path]:
        """
        Return all files in all nested subdirectories.
        """
        dir_path = cls._to_path(directory)
        if not dir_path.exists():
            return []
        return [p for p in dir_path.rglob("*") if p.is_file()]

    @classmethod
    def get_all_files_local_recursive(cls, subdirectory: PathLike) -> List[Path]:
        folder = cls.local_directory(subdirectory)
        return cls.get_all_files_recursive(folder)

    # ================================================================
    # Helpers
    # ================================================================

    @classmethod
    def _strip_outer_slashes(cls, s: str) -> str:
        if not isinstance(s, str):
            raise TypeError("Path must be a string")
        return s.lstrip("/\\").rstrip("/\\")

    @classmethod
    def _ensure_parent_dir(cls, path: Path) -> None:
        parent = path.parent
        if not parent.exists():
            parent.mkdir(parents=True, exist_ok=True)

    @classmethod
    def _to_path(cls, p: PathLike) -> Path:
        if isinstance(p, Path):
            return p.resolve()
        return Path(p).resolve()

    # ================================================================
    # Core I/O: bytes only
    # ================================================================

    @classmethod
    def load(cls, file_path: PathLike) -> bytes:
        """
        Load raw bytes from an explicit path.

        Caller decides how to interpret the bytes (text, image, etc.).
        """
        path = cls._to_path(file_path)

        if not path.is_file():
            raise FileNotFoundError(f"File not found: {path}")

        return path.read_bytes()

    @classmethod
    def load_local(
        cls,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> bytes:
        """
        Build a local file path via local_file() and load raw bytes.
        """
        path = cls.local_file(subdirectory=subdirectory, name=name, extension=extension)
        return cls.load(path)

    @classmethod
    def save(cls, data: bytes, file_path: PathLike) -> Path:
        """
        Save raw bytes to a specific path.

        - Creates parent directories if needed.
        - Returns the resolved Path actually written.
        """
        path = cls._to_path(file_path)
        cls._ensure_parent_dir(path)
        path.write_bytes(data)
        return path

    @classmethod
    def save_local(
        cls,
        data: bytes,
        subdirectory: str | None = None,
        name: str | None = None,
        extension: str | None = None,
    ) -> Path:
        """
        Build a local file path via local_file() and save raw bytes there.
        """
        path = cls.local_file(subdirectory=subdirectory, name=name, extension=extension)
        return cls.save(data, path)



# ===== file_utils.py =====

# file_utils.py
from __future__ import annotations
from typing import TYPE_CHECKING

from pathlib import Path
from typing import Optional

from filesystem.file_io import FileIO
from PIL import Image

if TYPE_CHECKING:
    # Only imported for type checkers / IDEs, not at runtime
    from image.bitmap import Bitmap

class FileUtils:

    # ================================================================
    # TEXT UTILITIES
    # ================================================================

    @classmethod
    def load_text(cls, file_path: Path, encoding: str = "utf-8") -> str:
        data = FileIO.load(file_path)
        return data.decode(encoding)

    @classmethod
    def load_local_text(cls, subdirectory: Optional[str], name: str, extension: str, encoding="utf-8") -> str:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.load_text(path, encoding)

    @classmethod
    def save_text(cls, text: str, file_path: Path, encoding: str = "utf-8") -> Path:
        data = text.encode(encoding)
        return FileIO.save(data, file_path)

    @classmethod
    def save_local_text(cls, text: str, subdirectory: Optional[str], name: str, extension: str, encoding="utf-8") -> Path:
        data = text.encode(encoding)
        return FileIO.save_local(data, subdirectory, name, extension)

    # ================================================================
    # IMAGE UTILITIES
    # ================================================================

    @classmethod
    def load_image(cls, file_path: Path) -> Image.Image:
        path = Path(file_path).resolve()
        if not path.is_file():
            raise FileNotFoundError(f"Image not found: {path}")
        img = Image.open(path)
        img.load()
        return img
    
    @classmethod
    def load_bitmap(cls, file_path: Path) -> Bitmap:
        image = cls.load_image(file_path)
        bitmap = Bitmap()
        bitmap.import_pillow(image)

    @classmethod
    def load_local_image(cls, subdirectory: Optional[str], name: str, extension="png") -> Image.Image:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.load_image(path)
    
    @classmethod
    def load_local_bitmap(cls, subdirectory: Optional[str], name: str, extension="png") -> Bitmap:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.load_bitmap(path)

    @classmethod
    def save_image(cls, image: Image.Image, file_path: Path) -> Path:
        path = Path(file_path).resolve()
        FileIO._ensure_parent_dir(path)
        image.save(path)
        return path

    @classmethod
    def save_local_image(cls, image: Image.Image, subdirectory: Optional[str], name: str, extension="png") -> Path:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.save_image(image, path)
    
    @classmethod
    def save_local_bitmap(cls, bitmap: Optional[Bitmap], subdirectory: Optional[str], name: str, extension="png") -> Path:
        path = FileIO.local_file(subdirectory, name, extension)
        return cls.save_image(bitmap.export_pillow(), path)



# ========== ROOT: /Users/naraptis/Desktop/Combustion/labels ==========

# ===== data_label.py =====

# data_label.py
from __future__ import annotations

from typing import Any, Dict
from labels.pixel_bag import PixelBag

class DataLabel:
    """
    Associates a string name with a PixelBag.

    JSON format:

        {
            "name": "some_label_name",
            "pixels": [ { "y": ..., "x_start": ..., "x_end": ... }, ... ]
        }
    """

    def __init__(self, name: str, pixel_bag: PixelBag | None = None) -> None:
        self.name: str = name
        self.pixel_bag: PixelBag = pixel_bag if pixel_bag is not None else PixelBag()


    # --------------------------------------------------
    # PixelBag passthrough wrappers
    # --------------------------------------------------
    def clear(self) -> None:
        self.pixel_bag.clear()

    def add(self, x: int, y: int) -> None:
        self.pixel_bag.add(x, y)

    def remove(self, x: int, y: int) -> None:
        self.pixel_bag.remove(x, y)

    def contains(self, x: int, y: int) -> bool:
        return self.pixel_bag.contains(x, y)

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "pixels": self.pixel_bag.to_json(),
        }

    @staticmethod
    def from_json(data: Dict[str, Any]) -> "DataLabel":
        name = data.get("name", "")
        pixels_json = data.get("pixels", [])
        bag = PixelBag.from_json(pixels_json)
        return DataLabel(name=name, pixel_bag=bag)

    # --------------------------------------------------
    # Utility / debug printing (summary style)
    # --------------------------------------------------
    def __repr__(self) -> str:
        """
        One-line compact summary, e.g.:

            DataLabel(name="lymph",
                      bag=PixelBag(count=100, median=(15,35), size=(10,10)))

        If bag is empty:

            DataLabel(name="lymph", bag=PixelBag(count=0))
        """
        return f'DataLabel(name="{self.name}", bag={self.pixel_bag})'



# ===== data_label_collection.py =====

# data_label_collection.py
from __future__ import annotations

from typing import Any, Dict, List, Iterable

from labels.data_label import DataLabel

class DataLabelCollection:
    """
    A simple list of DataLabel objects.

    Multiple labels may share the same name. Each DataLabel typically
    represents one instance (one PixelBag region).
    """

    def __init__(self, labels: List[DataLabel] | None = None) -> None:
        self.labels: List[DataLabel] = labels or []

    # --------------------------------------------------
    # Basic operations
    # --------------------------------------------------
    def add_label(self, label: DataLabel) -> None:
        """
        Append a label. Multiple labels may have the same name.
        """
        self.labels.append(label)

    def remove_label(self, label: DataLabel) -> None:
        """
        Remove this exact label object from the collection, if present.
        Does nothing if the label is not in the collection.
        """
        try:
            self.labels.remove(label)
        except ValueError:
            # label not in list; ignore
            pass

    def get_labels_by_name(self, name: str) -> List[DataLabel]:
        """
        Return all labels whose name matches the given name.
        May return an empty list.
        """
        return [lbl for lbl in self.labels if lbl.name == name]

    def first_label(self, name: str) -> DataLabel | None:
        """
        Convenience: return the first label with this name, or None.
        """
        for lbl in self.labels:
            if lbl.name == name:
                return lbl
        return None

    # --------------------------------------------------
    # JSON serialization (array only)
    # --------------------------------------------------
    def to_json(self) -> List[Dict[str, Any]]:
        """
        Return a JSON-compatible list of label dicts, no wrapper.
        """
        return [label.to_json() for label in self.labels]

    @staticmethod
    def from_json(data: List[Dict[str, Any]]) -> "DataLabelCollection":
        """
        Parse a list of label objects.
        """
        labels = [DataLabel.from_json(item) for item in data]
        return DataLabelCollection(labels=labels)

    # --------------------------------------------------
    # Helpers
    # --------------------------------------------------
    def __len__(self):
        return len(self.labels)

    def __iter__(self) -> Iterable[DataLabel]:
        return iter(self.labels)

    def _sorted_labels(self) -> List[DataLabel]:
        """
        Return labels sorted by:
          1) name (alphabetical)
          2) median.y  (ascending)
          3) median.x  (ascending)

        Uses PixelBag.summary().median so we don't have to look at stripes.
        Empty bags get a large sentinel so they sort last within a name.
        """
        if not self.labels:
            return []

        def sort_key(label: DataLabel):
            name = label.name
            summary = label.pixel_bag.summary()
            median = summary.get("median")

            if median is None:
                # Empty bag: push to the end for that name
                my = 10**9
                mx = 10**9
            else:
                mx, my = median  # median is (x, y)

            return (name, my, mx)

        return sorted(self.labels, key=sort_key)

    def __repr__(self) -> str:
        """
        Compact summary of the collection plus one-line summary per label, e.g.:

            DataLabelCollection(count=2):
                DataLabel(name="basal", bag=PixelBag(...))
                DataLabel(name="lymph", bag=PixelBag(...))
        """
        count = len(self.labels)
        if count == 0:
            return "DataLabelCollection(count=0)"

        lines: List[str] = [f"DataLabelCollection(count={count}):"]
        for label in self._sorted_labels():
            lines.append(f"    {label!r}")
        return "\n".join(lines)
    


# ===== image_annotation_document.py =====

# image_annotation_document.py
from __future__ import annotations

from typing import Any, Dict, List
from labels.data_label_collection import DataLabelCollection

class ImageAnnotationDocument:
    """
    Top-level container for annotations for a single image.

    Fields:
      - name:             Logical name for this document (often the JSON filename).
      - width:            Image width in pixels.
      - height:           Image height in pixels.
      - data:             DataLabelCollection holding all individual labels.
      - data_label_names: Derived list of label names present in `data`.
    """

    def __init__(
        self,
        name: str,
        width: int,
        height: int,
        data: DataLabelCollection | None = None,
    ) -> None:
        self.name: str = name
        self.width: int = int(width)
        self.height: int = int(height)
        # data is conceptually non-optional; default to empty collection if None
        self.data: DataLabelCollection = data if data is not None else DataLabelCollection()

    # --------------------------------------------------
    # Derived properties
    # --------------------------------------------------
    @property
    def data_label_names(self) -> List[str]:
        """
        Return a sorted list of unique label names present in this document's data.
        """
        names = {label.name for label in self.data}
        return sorted(names)

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> Dict[str, Any]:
        """
        Return a JSON-compatible dict representing this document.

        Layout:

        {
          "name":             str,
          "width":            int,
          "height":           int,
          "data_label_names": [str, ...],
          "labels":           [ ... DataLabel.to_json() ... ]
        }

        Note: data_label_names is derived from `data` at serialization time.
        """
        return {
            "name": self.name,
            "width": self.width,
            "height": self.height,
            "data_label_names": self.data_label_names,
            "labels": self.data.to_json(),
        }

    @staticmethod
    def from_json(data: Dict[str, Any]) -> "ImageAnnotationDocument":
        """
        Parse an ImageAnnotationDocument from a JSON-compatible dict.

        data_label_names from JSON are currently ignored as a source of truth,
        since they can always be recomputed from the label data. They are
        still read (if present) to allow future validation if desired.
        """
        name = data.get("name", "")
        width = int(data.get("width", 0))
        height = int(data.get("height", 0))

        labels_raw = data.get("labels", []) or []
        dlc = DataLabelCollection.from_json(labels_raw)

        # data_label_names = data.get("data_label_names", [])  # optional; not required

        return ImageAnnotationDocument(
            name=name,
            width=width,
            height=height,
            data=dlc,
        )

    # --------------------------------------------------
    # Debug / repr
    # --------------------------------------------------
    def __repr__(self) -> str:
        """
        Compact summary plus an indented listing of labels via
        DataLabelCollection.__repr__.

        Example:

            ImageAnnotationDocument(name="sample_01",
                                    size=(256, 256),
                                    data_label_names=['Alphacyte', 'Lymphocyte'],
                                    label_count=3):
                DataLabel(name="Alphacyte", bag=PixelBag(...))
                DataLabel(name="Lymphocyte", bag=PixelBag(...))
                ...
        """
        label_count = len(self.data)
        header = (
            f'ImageAnnotationDocument('
            f'name="{self.name}", '
            f'size=({self.width}, {self.height}), '
            f'data_label_names={self.data_label_names}, '
            f'label_count={label_count})'
        )

        if label_count == 0:
            return header

        # Indent the DataLabelCollection repr by 4 spaces
        dlc_lines = repr(self.data).splitlines()
        indented_dlc = "\n".join("    " + line for line in dlc_lines)

        return header + ":\n" + indented_dlc



# ===== pixel_bag.py =====

# pixel_bag.py
from __future__ import annotations
from typing import Any, List
from labels.pixel_bag_run_length import PixelBagRunLength
from labels.pixel_bag_run_length_stripe import PixelBagRunLengthStripe

class PixelBag:
    """
    Stores a set of (x, y) integer pixel positions.
    Does not store duplicates (internally a set),
    but add/remove semantics allow double-add and remove-nonexistent
    without raising exceptions.
    """

    def __init__(self) -> None:
        self._set = set()   # stores (x, y)

    # --------------------------------------------------
    # Basic operations
    # --------------------------------------------------
    def clear(self) -> None:
        self._set.clear()

    def add(self, x: int, y: int) -> None:
        """Add a pixel. Adding an existing pixel is allowed and ignored."""
        self._set.add((int(x), int(y)))

    def remove(self, x: int, y: int) -> None:
        """Remove a pixel. Removing a missing pixel is allowed and ignored."""
        self._set.discard((int(x), int(y)))  # discard() never raises

    def contains(self, x: int, y: int) -> bool:
        """Check if a pixel exists in the bag."""
        return (int(x), int(y)) in self._set

    # --------------------------------------------------
    # Bounding box helpers
    # --------------------------------------------------
    @property
    def xmin(self):
        if not self._set:
            return None
        return min(px for (px, _) in self._set)

    @property
    def xmax(self):
        if not self._set:
            return None
        return max(px for (px, _) in self._set)

    @property
    def ymin(self):
        if not self._set:
            return None
        return min(py for (_, py) in self._set)

    @property
    def ymax(self):
        if not self._set:
            return None
        return max(py for (_, py) in self._set)
    
    @property
    def frame(self):
        if not self._set:
            return (0, 0, 0, 0)

        xr = self.xrange()
        yr = self.yrange()
        
        width  = xr.stop - xr.start
        height = yr.stop - yr.start

        return (xr.start, yr.start, width, height)

    # --------------------------------------------------
    # Ranges for easy looping
    # --------------------------------------------------
    def xrange(self):
        """
        Return range(xmin, xmax+1).
        If empty, return range(0).
        """
        if not self._set:
            return range(0)
        return range(self.xmin, self.xmax + 1)

    def yrange(self):
        """
        Return range(ymin, ymax+1).
        If empty, return range(0).
        """
        if not self._set:
            return range(0)
        return range(self.ymin, self.ymax + 1)

    # --------------------------------------------------
    # Utility
    # --------------------------------------------------
    def __len__(self):
        return len(self._set)

    def __iter__(self):
        """Iterate over (x, y) pairs."""
        return iter(self._set)

    def summary(self) -> dict:
        """
        Return summary statistics:

            {
            "count": int,
            "median": (x_med, y_med) | None,
            "size": (width, height)
            }

        width  = xmax - xmin + 1
        height = ymax - ymin + 1
        """
        count = len(self._set)
        if count == 0:
            return {
                "count": 0,
                "median": None,
                "size": (0, 0),
            }

        xs = [x for (x, _) in self._set]
        ys = [y for (_, y) in self._set]

        xs_sorted = sorted(xs)
        ys_sorted = sorted(ys)
        mid = count // 2

        median_x = xs_sorted[mid]
        median_y = ys_sorted[mid]

        xmin = self.xmin
        xmax = self.xmax
        ymin = self.ymin
        ymax = self.ymax

        width = (xmax - xmin + 1) if xmin is not None and xmax is not None else 0
        height = (ymax - ymin + 1) if ymin is not None and ymax is not None else 0

        return {
            "count": count,
            "median": (median_x, median_y),
            "size": (width, height),
        }


    def __repr__(self):
        """
        Compact one-line summary:

            PixelBag(count=67, median=(46,77), size=(80, 111))
        """
        info = self.summary()
        count = info["count"]

        if count == 0:
            return "PixelBag(count=0)"

        mx, my = info["median"]
        w, h = info["size"]

        return (
            f"PixelBag(count={count}, "
            f"median=({mx}, {my}), "
            f"size=({w}, {h}))"
        )


    # --------------------------------------------------
    # Run-length conversion
    # --------------------------------------------------
    def to_run_length(self) -> "PixelBagRunLength":
        result = PixelBagRunLength()

        _xmin = self.xmin
        _xmax = self.xmax
        if _xmin is None or _xmax is None:
            return result

        for y in self.yrange():
            x = _xmin
            while x <= _xmax:
                if self.contains(x, y):
                    x_start = x
                    x_end = x
                    x += 1
                    while x <= _xmax and self.contains(x, y):
                        x_end = x
                        x += 1
                    result.add_stripe(PixelBagRunLengthStripe(y, x_start, x_end))
                else:
                    x += 1
        return result

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> List[Any]:
        """
        Serialize this PixelBag to a JSON-compatible list of run-length
        stripe objects:
            [ { "y": ..., "x_start": ..., "x_end": ... }, ... ]
        """
        rle = self.to_run_length()
        return rle.to_json()

    @staticmethod
    def from_json(data: List[Any]) -> "PixelBag":
        """
        Deserialize a PixelBag from a JSON-compatible list produced
        by PixelBag.to_json().

        Reconstructs all (x, y) pixels from the run-length stripes.
        """
        rle = PixelBagRunLength.from_json(data)
        bag = PixelBag()
        for stripe in rle.stripes:
            y = stripe.y
            for x in range(stripe.x_start, stripe.x_end + 1):
                bag.add(x, y)
        return bag



# ===== pixel_bag_run_length.py =====

# pixel_bag_run_length.py
from __future__ import annotations
from typing import Any, Iterable, List

from labels.pixel_bag_run_length_stripe import PixelBagRunLengthStripe

class PixelBagRunLength:
    """
    Run-length representation of a PixelBag:
    a list of horizontal stripes.
    """

    def __init__(self, stripes: List[PixelBagRunLengthStripe] | None = None) -> None:
        self.stripes: List[PixelBagRunLengthStripe] = stripes or []

    # --------------------------------------------------
    # JSON serialization
    # --------------------------------------------------
    def to_json(self) -> List[Any]:
        return [stripe.to_json() for stripe in self.stripes]

    @staticmethod
    def from_json(data: List[Any]) -> "PixelBagRunLength":
        stripes = [PixelBagRunLengthStripe.from_json(item) for item in data]
        return PixelBagRunLength(stripes=stripes)

    # --------------------------------------------------
    # Utility
    # --------------------------------------------------
    def add_stripe(self, stripe: PixelBagRunLengthStripe) -> None:
        self.stripes.append(stripe)

    def __len__(self) -> int:
        return len(self.stripes)

    def __iter__(self):
        return iter(self.stripes)

    # -------- central sorting helper --------
    @staticmethod
    def sorted_stripes(
        stripes: Iterable[PixelBagRunLengthStripe],
    ) -> List[PixelBagRunLengthStripe]:
        return sorted(stripes, key=lambda s: (s.y, s.x_start))

    def sorted(self) -> List[PixelBagRunLengthStripe]:
        return PixelBagRunLength.sorted_stripes(self.stripes)

    # --------------------------------------------------
    # One-line summary repr
    # --------------------------------------------------
    def __repr__(self) -> str:
        """
        Compact one-line summary:
        PixelBagRunLength(count=3, stripes=[Stripe(y=10,3→5), Stripe(y=11,7→7)])
        """
        if not self.stripes:
            return "PixelBagRunLength(count=0, stripes=[])"

        parts = []
        for s in self.sorted():
            parts.append(f"Stripe(y={s.y},{s.x_start}→{s.x_end})")

        stripes_str = ", ".join(parts)
        return f"PixelBagRunLength(count={len(self.stripes)}, stripes=[{stripes_str}])"



# ===== pixel_bag_run_length_stripe.py =====

# pixel_bag_run_length_stripe.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict

@dataclass
class PixelBagRunLengthStripe:
    """
    Represents a horizontal run of pixels at a fixed y:
        x in [x_start, x_end] inclusive.
    """
    y: int
    x_start: int
    x_end: int

    def to_json(self) -> Dict[str, Any]:
        """
        Serialize this stripe to a JSON-compatible dict.
        """
        return {
            "y": int(self.y),
            "x_start": int(self.x_start),
            "x_end": int(self.x_end),
        }

    @staticmethod
    def from_json(data: Dict[str, Any]) -> "PixelBagRunLengthStripe":
        """
        Deserialize a stripe from a JSON-compatible dict.
        Expects keys: "y", "x_start", "x_end".
        """
        return PixelBagRunLengthStripe(
            y=int(data["y"]),
            x_start=int(data["x_start"]),
            x_end=int(data["x_end"]),
        )

    # --------------------------------------------------
    # Debug / printing helpers
    # --------------------------------------------------
    def repr_str(self, indent: int = 0) -> str:
        """
        Return a single-line string representation, with leading tabs
        based on indent depth.
        """
        prefix = "\t" * max(indent, 0)
        return f"{prefix}(y={self.y}, x_start={self.x_start}, x_end={self.x_end})"

    def __repr__(self) -> str:
        """
        Default repr with no indentation.
        """
        return self.repr_str(indent=0)



